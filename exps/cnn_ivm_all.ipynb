{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "import gc\n",
    "import math\n",
    "from scipy import ndimage\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import random\n",
    "import pickle\n",
    "import os\n",
    "import scipy\n",
    "\n",
    "from skimage import data, img_as_float\n",
    "from skimage.measure import compare_ssim as ssim\n",
    "\n",
    "import sys\n",
    "sys.path.append('../code')\n",
    "from python.commons import full_inference_e2e, inc_inference_e2e, adaptive_drilldown, generate_heatmap, load_dict_from_hdf5\n",
    "from python.imagenet_classes import class_names\n",
    "from python.vgg16 import VGG16\n",
    "from python.resnet18 import ResNet18\n",
    "from python.inception3 import Inception3\n",
    "\n",
    "image_file_path = \"../code/python/dog_resized.jpg\"\n",
    "\n",
    "random.seed(45)\n",
    "np.random.seed(45)\n",
    "\n",
    "torch.set_num_threads(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [ResNet18]\n",
    "patch_sizes = [4, 8, 16]\n",
    "strides = [1, 2, 4, 8]\n",
    "taus = [1.0, 0.9, 0.8, 0.7, 0.6, 0.5, 0.4]\n",
    "c = 0.5\n",
    "\n",
    "dataset = 'OCT'\n",
    "n_labels = 4\n",
    "show = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_files = []\n",
    "temp = os.listdir('../data/oct/test/DRUSEN')\n",
    "for name in temp:\n",
    "    if name.endswith('jpeg'):\n",
    "        image_files.append('../data/oct/test/DRUSEN/'+name)\n",
    "\n",
    "temp = os.listdir('../data/oct/test/DME')\n",
    "for name in temp:\n",
    "    if name.endswith('jpeg'):\n",
    "        image_files.append('../data/oct/test/DME/'+name)\n",
    "        \n",
    "temp = os.listdir('../data/oct/test/CNV')\n",
    "for name in temp:\n",
    "    if name.endswith('jpeg'):\n",
    "        image_files.append('../data/oct/test/CNV/'+name)\n",
    "        \n",
    "        \n",
    "temp = os.listdir('../data/oct/test/NORMAL')        \n",
    "for name in temp:\n",
    "    if name.endswith('jpeg'):\n",
    "        image_files.append('../data/oct/test/NORMAL/'+name)\n",
    "\n",
    "file_amount = 8\n",
    "image_files = random.sample(image_files, file_amount)\n",
    "\n",
    "weight_files = [\n",
    "#     '../code/python/vgg16_weights_ptch.h5',\n",
    "    '../code/python/resnet18_weights_ptch.h5',\n",
    "#     '../code/python/inception3_weights_ptch.h5'\n",
    "]\n",
    "\n",
    "fine_tuned_weight_files = [\n",
    "#     './oct_vgg16_ptch.h5',\n",
    "    './oct_resnet18_ptch.h5',\n",
    "#     './oct_inception3_ptch.h5'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_confidence_interval(data, confidence=0.95):\n",
    "    a = 1.0 * np.array(data)\n",
    "    n = len(a)\n",
    "    m, se = np.mean(a), scipy.stats.sem(a)\n",
    "    h = se * scipy.stats.t.ppf((1 + confidence) / 2., n-1)\n",
    "    if math.isnan(h):\n",
    "        h = 0\n",
    "    return m, h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inc_inference(beta, patch_size=4, stride=1, adaptive=False, gpu=True, version='v1', weights_data=None):\n",
    "    if gpu:\n",
    "        batch_size = 256\n",
    "    else:\n",
    "        batch_size = 16\n",
    "\n",
    "    torch.cuda.synchronize()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        x = inc_inference_e2e(model, image_file_path, patch_size, stride,\n",
    "                              batch_size=batch_size, beta=beta, gpu=gpu, version=version,\n",
    "                             image_size=image_size, x_size=x_size, y_size=y_size, weights_data=weights_data,\n",
    "                              n_labels=n_labels, c=c)\n",
    "    \n",
    "    torch.cuda.synchronize()\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "log_file = open('cnn_ivm_all.log', 'w')\n",
    "\n",
    "for model, weight_file, fine_tuned_weight_file in zip(models, weight_files, fine_tuned_weight_files):\n",
    "\n",
    "    weights_data_gpu = load_dict_from_hdf5(weight_file, gpu=True)\n",
    "    file_tuned_weight_data_gpu = load_dict_from_hdf5(fine_tuned_weight_file, gpu=True)\n",
    "\n",
    "    weights_data = load_dict_from_hdf5(weight_file, gpu=False)\n",
    "    file_tuned_weight_data = load_dict_from_hdf5(fine_tuned_weight_file, gpu=False)\n",
    "    \n",
    "    if model == VGG16:\n",
    "        weights_data_gpu['fc8_W:0'] = file_tuned_weight_data_gpu['fc8_W:0']\n",
    "        weights_data_gpu['fc8_b:0'] = file_tuned_weight_data_gpu['fc8_b:0']\n",
    "        weights_data['fc8_W:0'] = file_tuned_weight_data['fc8_W:0']\n",
    "        weights_data['fc8_b:0'] = file_tuned_weight_data['fc8_b:0']\n",
    "    elif model == ResNet18:\n",
    "        weights_data_gpu['fc:w'] = file_tuned_weight_data_gpu['fc:w']\n",
    "        weights_data_gpu['fc:b'] = file_tuned_weight_data_gpu['fc:b']\n",
    "        weights_data['fc:w'] = file_tuned_weight_data['fc:w']\n",
    "        weights_data['fc:b'] = file_tuned_weight_data['fc:b']\n",
    "    elif model == Inception3:\n",
    "        weights_data_gpu['482.fc.weight'] = file_tuned_weight_data_gpu['482.fc.weight']\n",
    "        weights_data_gpu['483.fc.bias'] = file_tuned_weight_data_gpu['483.fc.bias']\n",
    "        weights_data['482.fc.weight'] = file_tuned_weight_data['482.fc.weight']\n",
    "        weights_data['483.fc.bias'] = file_tuned_weight_data['483.fc.bias']\n",
    "        \n",
    "        \n",
    "    for patch_size in patch_sizes:\n",
    "        for stride in strides:\n",
    "\n",
    "            if model == Inception3:\n",
    "                image_size = 299\n",
    "                x_size = 299\n",
    "                y_size = 299\n",
    "            else:\n",
    "                image_size = 224\n",
    "                x_size = 224\n",
    "                y_size = 224\n",
    "\n",
    "                    \n",
    "            times_gpu_custom_global = []\n",
    "            speedups_gpu_custom_global = []\n",
    "            score_gpu_custom_global = []\n",
    "\n",
    "            times_gpu_global = []\n",
    "            speedups_gpu_global = []\n",
    "\n",
    "            times_cpu_global = []\n",
    "            speedups_cpu_global = []\n",
    "            score_cpu_global = []\n",
    "            \n",
    "            for image_file_path in image_files:\n",
    "                torch.cuda.synchronize()\n",
    "                prev_time = time.time()\n",
    "                with torch.no_grad():\n",
    "                    x = full_inference_e2e(model, image_file_path, patch_size, stride,\n",
    "                                           batch_size=128, gpu=True, image_size=image_size,\n",
    "                                           x_size=x_size, y_size=y_size, weights_data=weights_data_gpu,\n",
    "                                          n_labels=n_labels, c=c)\n",
    "\n",
    "                torch.cuda.synchronize()\n",
    "                full_inference_gpu_time = time.time() - prev_time\n",
    "\n",
    "                torch.cuda.synchronize()\n",
    "                prev_time = time.time()\n",
    "                with torch.no_grad():\n",
    "                    x = full_inference_e2e(model, image_file_path, patch_size, stride,\n",
    "                                           batch_size=16, gpu=False, image_size=image_size,\n",
    "                                           x_size=x_size, y_size=y_size, weights_data=weights_data,\n",
    "                                          n_labels=n_labels, c=c)\n",
    "\n",
    "                torch.cuda.synchronize()\n",
    "                full_inference_cpu_time = time.time() - prev_time\n",
    "\n",
    "                label = str(model).split('.')[-1][:-2]+\" Full Inference GPU Time: \" + str(full_inference_gpu_time)\n",
    "                print(label)\n",
    "                log_file.write(label+\"\\n\")\n",
    "                label = str(model).split('.')[-1][:-2]+\" Full Inference CPU Time: \" + str(full_inference_cpu_time)\n",
    "                print(label)\n",
    "                log_file.write(label+\"\\n\")\n",
    "\n",
    "\n",
    "                orig_hm = generate_heatmap(image_file_path, x, show=show, width=image_size)\n",
    "\n",
    "                gc.collect()\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "                times_gpu_custom = []\n",
    "                speedups_gpu_custom = []\n",
    "                score_gpu_custom = []\n",
    "\n",
    "                times_gpu = []\n",
    "                speedups_gpu = []\n",
    "\n",
    "                times_cpu = []\n",
    "                speedups_cpu = []\n",
    "                score_cpu = []\n",
    "\n",
    "                for beta in taus:    \n",
    "                    #CPU\n",
    "                    prev_time = time.time()\n",
    "                    x = inc_inference(beta, patch_size=patch_size, stride=stride, gpu=False, version='v2',\n",
    "                                      weights_data=weights_data)\n",
    "                    inc_inference_time = time.time()-prev_time\n",
    "                    times_cpu.append(inc_inference_time)\n",
    "                    speedups_cpu.append(full_inference_cpu_time/inc_inference_time)\n",
    "\n",
    "                    hm = generate_heatmap(image_file_path, x, show=show, width=image_size)\n",
    "\n",
    "                    if hm.shape[0] < 7:\n",
    "                        win_size=3\n",
    "                    else:\n",
    "                        win_size=None\n",
    "\n",
    "                    ssim_score = ssim(orig_hm, hm, data_range=255, multichannel=True, win_size=win_size)\n",
    "                    score_cpu.append(ssim_score)\n",
    "                    label = str(model).split('.')[-1][:-2]+\" CPU - BETA: \" + str(beta) +\" Inference Time: \" +\\\n",
    "                        str(inc_inference_time) + \" SSIM: \" + str(ssim_score)\n",
    "                    print(label)\n",
    "                    log_file.write(label+\"\\n\")\n",
    "                    gc.collect()\n",
    "                    torch.cuda.empty_cache()\n",
    "                    \n",
    "                    #GPU\n",
    "                    prev_time = time.time()\n",
    "                    x = inc_inference(beta, patch_size=patch_size, stride=stride, gpu=True, version='v2',\n",
    "                                      weights_data=weights_data_gpu)\n",
    "                    inc_inference_time = time.time()-prev_time\n",
    "                    times_gpu.append(inc_inference_time)\n",
    "                    speedups_gpu.append(full_inference_gpu_time/inc_inference_time)\n",
    "                    gc.collect()\n",
    "                    torch.cuda.empty_cache()\n",
    "                    label = str(model).split('.')[-1][:-2]+\" GPU: \" + str(beta) +\" Inference Time: \" +\\\n",
    "                        str(inc_inference_time)\n",
    "                    print(label)\n",
    "                    log_file.write(label+\"\\n\")                    \n",
    "\n",
    "                    #GPU Custom\n",
    "                    prev_time = time.time()\n",
    "                    x = inc_inference(beta, patch_size=patch_size, stride=stride, gpu=True, version='v1',\n",
    "                                      weights_data=weights_data_gpu)\n",
    "                    inc_inference_time = time.time()-prev_time\n",
    "                    times_gpu_custom.append(inc_inference_time)\n",
    "                    speedups_gpu_custom.append(full_inference_gpu_time/inc_inference_time)\n",
    "                    hm = generate_heatmap(image_file_path, x, show=show, width=image_size)\n",
    "                    if hm.shape[0] < 7:\n",
    "                        win_size=3\n",
    "                    else:\n",
    "                        win_size=None\n",
    "                    \n",
    "                    ssim_score = ssim(orig_hm, hm, data_range=255, multichannel=True, win_size=win_size)\n",
    "                    score_gpu_custom.append(ssim_score)\n",
    "                    label = str(model).split('.')[-1][:-2]+\" GPU Custom - BETA: \" + str(beta) + \\\n",
    "                        \" Inference Time: \" + str(inc_inference_time) + \" SSIM: \" + str(ssim_score)\n",
    "                    print(label)\n",
    "                    log_file.write(label+\"\\n\")              \n",
    "                    \n",
    "                    gc.collect()\n",
    "                    torch.cuda.empty_cache()\n",
    "                    \n",
    "                    \n",
    "                times_gpu_custom_global.append(times_gpu_custom)\n",
    "                speedups_gpu_custom_global.append(speedups_gpu_custom)\n",
    "                score_gpu_custom_global.append(score_gpu_custom)\n",
    "\n",
    "                times_gpu_global.append(times_gpu)\n",
    "                speedups_gpu_global.append(speedups_gpu)\n",
    "\n",
    "                times_cpu_global.append(times_cpu)\n",
    "                speedups_cpu_global.append(speedups_cpu)\n",
    "                score_cpu_global.append(score_cpu)\n",
    "                \n",
    "\n",
    "            fig = plt.figure(figsize=(4,2))\n",
    "            ax1 = plt.subplot(1, 1, 1)\n",
    "\n",
    "            temp_mean = []\n",
    "            temp_ci = []\n",
    "            for temp in zip(*score_gpu_custom_global):\n",
    "                m, h = mean_confidence_interval(temp)\n",
    "                temp_mean.append(m)\n",
    "                temp_ci.append(h)\n",
    "            ax1.errorbar(taus, temp_mean, yerr=temp_ci, marker='o', color='tab:blue')\n",
    "\n",
    "            ax1.grid()\n",
    "            #ax1.set_xlabel(r'$\\tau$')\n",
    "            #ax1.set_ylabel('SSIM', color='tab:blue')\n",
    "            ax1.tick_params(axis='y', labelcolor='tab:blue')\n",
    "            ax1.xaxis.set_ticks(np.arange(0.4, 1.1, 0.1))\n",
    "\n",
    "            ax2 = ax1.twinx()\n",
    "\n",
    "            temp_mean = []\n",
    "            temp_ci = []\n",
    "            for temp in zip(*speedups_cpu_global):\n",
    "                m, h = mean_confidence_interval(temp)\n",
    "                temp_mean.append(m)\n",
    "                temp_ci.append(h)\n",
    "            ax2.errorbar(taus, temp_mean, yerr=temp_ci, marker='D', color='tab:red', label='CPU')\n",
    "\n",
    "            temp_mean = []\n",
    "            temp_ci = []\n",
    "            for temp in zip(*speedups_gpu_global):\n",
    "                m, h = mean_confidence_interval(temp)\n",
    "                temp_mean.append(m)\n",
    "                temp_ci.append(h)\n",
    "            ax2.errorbar(taus, temp_mean, yerr=temp_ci, marker='^', color='tab:red', label='GPU')\n",
    "\n",
    "            temp_mean = []\n",
    "            temp_ci = []\n",
    "            for temp in zip(*speedups_gpu_custom_global):\n",
    "                m, h = mean_confidence_interval(temp)\n",
    "                temp_mean.append(m)\n",
    "                temp_ci.append(h)\n",
    "            ax2.errorbar(taus, temp_mean, yerr=temp_ci, marker='s', color='tab:red', label='GPU Custom')\n",
    "\n",
    "            #ax2.set_ylabel('Speedup', color='tab:red')\n",
    "            ax2.tick_params(axis='y', labelcolor='tab:red')\n",
    "\n",
    "            #fig.legend(loc='lower center', ncol=3, bbox_to_anchor=(0.5,-0.025), frameon=False)\n",
    "            #fig.tight_layout()\n",
    "            fig_label = str(model).split('.')[-1][:-2]+\"/\"+str(dataset)+\"/P=\"+str(patch_size)+\"/S=\"+str(stride)\n",
    "            fig.suptitle(fig_label)\n",
    "            plt.savefig('./plots/'+fig_label.replace('/','-')+'.jpg')\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
