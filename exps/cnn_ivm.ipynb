{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import time\n",
    "import gc\n",
    "import math\n",
    "from scipy import ndimage\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import pickle\n",
    "\n",
    "from skimage import data, img_as_float\n",
    "from skimage.measure import compare_ssim as ssim\n",
    "\n",
    "import sys\n",
    "sys.path.append('../code')\n",
    "from python.commons import full_inference_e2e, inc_inference_e2e, adaptive_drilldown, generate_heatmap\n",
    "from python.imagenet_classes import class_names\n",
    "from python.vgg16 import VGG16\n",
    "from python.resnet18 import ResNet18\n",
    "from python.inception3 import Inception3\n",
    "\n",
    "image_file_path = \"../code/python/dog_resized.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_num_threads(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VGG16\n",
    "patch_size = 16\n",
    "stride = 4\n",
    "dataset = 'ImageNet'\n",
    "\n",
    "show = True\n",
    "    \n",
    "if model == Inception3:\n",
    "    image_size = 299\n",
    "    x_size = 299\n",
    "    y_size = 299\n",
    "else:\n",
    "    image_size = 224\n",
    "    x_size = 224\n",
    "    y_size = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "torch.cuda.synchronize()\n",
    "prev_time = time.time()\n",
    "with torch.no_grad():\n",
    "    x, prob, logit_index = full_inference_e2e(model, image_file_path, patch_size, stride,\n",
    "                           batch_size=128, gpu=True, image_size=image_size, x_size=x_size, y_size=y_size)\n",
    "\n",
    "torch.cuda.synchronize()\n",
    "full_inference_gpu_time = time.time() - prev_time\n",
    "\n",
    "torch.cuda.synchronize()\n",
    "prev_time = time.time()\n",
    "with torch.no_grad():\n",
    "    x, prob, logit_index = full_inference_e2e(model, image_file_path, patch_size, stride,\n",
    "                           batch_size=16, gpu=False, image_size=image_size, x_size=x_size, y_size=y_size)\n",
    "\n",
    "torch.cuda.synchronize()\n",
    "full_inference_cpu_time = time.time() - prev_time\n",
    "\n",
    "\n",
    "print(\"Full Inference GPU Time: \" + str(full_inference_gpu_time))\n",
    "print(\"Full Inference CPU Time: \" + str(full_inference_cpu_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_hm = generate_heatmap(image_file_path, x, show=show, label=class_names[logit_index], prob=prob, width=image_size)\n",
    "\n",
    "output = open('temp', 'w')\n",
    "pickle.dump(orig_hm, output)\n",
    "output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inc_inference(beta, patch_size=4, stride=1, adaptive=False, gpu=True, version='v1'):\n",
    "    #model specific configurations\n",
    "    if gpu:\n",
    "        batch_size = 256\n",
    "    else:\n",
    "        batch_size = 16\n",
    "        \n",
    "    if gpu:\n",
    "        torch.cuda.synchronize()\n",
    "    \n",
    "    if not adaptive:\n",
    "        with torch.no_grad():\n",
    "            x, prob, logit_index = inc_inference_e2e(model, image_file_path, patch_size, stride,\n",
    "                                  batch_size=batch_size, beta=beta, gpu=gpu, version=version,\n",
    "                                 image_size=image_size, x_size=x_size, y_size=y_size)\n",
    "    else:\n",
    "        with torch.no_grad():\n",
    "            x, prob, logit_index = adaptive_drilldown(model, image_file_path, patch_size, stride,\n",
    "                                    batch_size=batch_size, beta=beta, percentile=20)\n",
    "    if gpu:\n",
    "        torch.cuda.synchronize()\n",
    "\n",
    "    return x, prob, logit_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "orig_hm = pickle.load(open('temp', 'r'))\n",
    "\n",
    "times_gpu_custom = []\n",
    "speedups_gpu_custom = []\n",
    "score_gpu_custom = []\n",
    "\n",
    "times_gpu = []\n",
    "speedups_gpu = []\n",
    "\n",
    "times_cpu = []\n",
    "speedups_cpu = []\n",
    "score_cpu = []\n",
    "\n",
    "taus = [1.0, 0.9, 0.8, 0.7, 0.6, 0.5, 0.4]\n",
    "\n",
    "for beta in taus:    \n",
    "    #CPU\n",
    "    prev_time = time.time()\n",
    "    x, prob, logit_index = inc_inference(beta, patch_size=patch_size, stride=stride, gpu=False, version='v2')\n",
    "    inc_inference_time = time.time()-prev_time\n",
    "    times_cpu.append(inc_inference_time)\n",
    "    speedups_cpu.append(full_inference_cpu_time/inc_inference_time)\n",
    "    \n",
    "    label = \"CPU - BETA: \" + str(beta) +\" Inference Time: \" + str(inc_inference_time)\n",
    "    print(label)\n",
    "    hm = generate_heatmap(image_file_path, x, show=show, label=class_names[logit_index], prob=prob,\n",
    "                          width=image_size)\n",
    "\n",
    "    if hm.shape[0] < 7:\n",
    "        win_size=3\n",
    "    else:\n",
    "        win_size=None\n",
    "\n",
    "    score_cpu.append(ssim(orig_hm, hm, data_range=255, multichannel=True, win_size=win_size))\n",
    "    \n",
    "    #GPU\n",
    "    prev_time = time.time()\n",
    "    x, prob, logit_index = inc_inference(beta, patch_size=patch_size, stride=stride, gpu=True, version='v2')\n",
    "    inc_inference_time = time.time()-prev_time\n",
    "    times_gpu.append(inc_inference_time)\n",
    "    speedups_gpu.append(full_inference_gpu_time/inc_inference_time)\n",
    "    \n",
    "    #GPU Custom\n",
    "    prev_time = time.time()\n",
    "    x, prob, logit_index = inc_inference(beta, patch_size=patch_size, stride=stride, gpu=True, version='v1')\n",
    "    inc_inference_time = time.time()-prev_time\n",
    "    times_gpu_custom.append(inc_inference_time)\n",
    "    speedups_gpu_custom.append(full_inference_gpu_time/inc_inference_time)\n",
    "    label = \"GPU Custom - BETA: \" + str(beta) +\" Inference Time: \" + str(inc_inference_time)\n",
    "    print(label)\n",
    "    hm = generate_heatmap(image_file_path, x, show=show, label=class_names[logit_index], prob=prob, width=image_size)\n",
    "    if hm.shape[0] < 7:\n",
    "        win_size=3\n",
    "    else:\n",
    "        win_size=None\n",
    "    score_gpu_custom.append(ssim(orig_hm, hm, data_range=255, multichannel=True, win_size=win_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(4,2))\n",
    "ax1 = plt.subplot(1, 1, 1)\n",
    "ax1.plot(taus, score_cpu, marker='x', color='tab:orange')\n",
    "ax1.plot(taus, score_gpu_custom, marker='o', color='tab:blue')\n",
    "ax1.grid()\n",
    "#ax1.set_xlabel(r'$\\tau$')\n",
    "#ax1.set_ylabel('SSIM', color='tab:blue')\n",
    "ax1.tick_params(axis='y', labelcolor='tab:blue')\n",
    "ax1.xaxis.set_ticks(np.arange(0.4, 1.1, 0.1))\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(taus, speedups_cpu, marker='D', color='tab:red', label='CPU')\n",
    "ax2.plot(taus, speedups_gpu, marker='^', color='tab:red', label='GPU')\n",
    "ax2.plot(taus, speedups_gpu_custom, marker='s', color='tab:red', label='GPU Custom')\n",
    "#ax2.set_ylabel('Speedup', color='tab:red')\n",
    "ax2.tick_params(axis='y', labelcolor='tab:red')\n",
    "\n",
    "#fig.legend(loc='lower center', ncol=3, bbox_to_anchor=(0.5,-0.025), frameon=False)\n",
    "fig.tight_layout()\n",
    "fig_label = str(model).split('.')[-1][:-2]+\"/\"+str(dataset)+\"/P=\"+str(patch_size)+\"/S=\"+str(stride)\n",
    "fig.suptitle(fig_label, y=1.05, x=0.53)\n",
    "plt.savefig('./plots/'+fig_label.replace('/','-')+'.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "orig_hm = pickle.load(open('temp', 'r'))\n",
    "\n",
    "times = []\n",
    "score = []\n",
    "\n",
    "for beta in [1.0, 0.7, 0.5, 0.4, 0.35, 0.3, 0.25, 0.2]:\n",
    "    prev_time = time.time()\n",
    "    x, prob, logit_index = inc_inference(beta, patch_size=patch_size, stride=stride, adaptive=True)\n",
    "    inc_inference_time = time.time()-prev_time\n",
    "    times.append(inc_inference_time)\n",
    "    \n",
    "    label = \"BETA: \" + str(beta) +\" Inference Time: \" + str(inc_inference_time)\n",
    "    print(label)\n",
    "    hm = generate_heatmap(image_file_path, x, show=True, label=class_names[logit_index], prob=prob)\n",
    "    score.append(ssim(orig_hm, hm, data_range=255, multichannel=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(times, score, marker='o')\n",
    "plt.grid()\n",
    "plt.xlabel('runtime (s)')\n",
    "plt.ylabel('SSIM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
