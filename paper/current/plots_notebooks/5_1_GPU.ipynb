{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision.models.alexnet import alexnet\n",
    "from torchvision.models.vgg import vgg16, vgg19\n",
    "from torchvision.models.resnet import resnet18, resnet50\n",
    "from torchvision.models.densenet import densenet121\n",
    "from torchvision.models.inception import Inception3 as inception3\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import sys\n",
    "import time\n",
    "import random\n",
    "import cv2\n",
    "import gc\n",
    "from matplotlib import gridspec\n",
    "\n",
    "sys.path.append('../../../code')\n",
    "\n",
    "from python.commons import full_inference_e2e_with_model, inc_inference_e2e_with_model\n",
    "from python.vgg16 import VGG16\n",
    "from python.resnet18 import ResNet18\n",
    "from python.inception3 import Inception3\n",
    "\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from plot_commons import get_ivm_patch_coordinates, calculate_ivm_flops, calculate_flops, mean_confidence_interval\n",
    "\n",
    "random.seed(45)\n",
    "np.random.seed(45)\n",
    "\n",
    "torch.set_num_threads(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inc_inference_selected_with_model(inc_model, file_path, patch_size, stride, patch_positions, batch_size=64, beta=1.0,\n",
    "                           x0=0, y0=0, image_size=224, x_size=224, y_size=224, gpu=True, version='v1',\n",
    "                           n_labels=1000, weights_data=None, loader=None, c=0.0):\n",
    "\n",
    "    if loader == None:\n",
    "        loader = transforms.Compose([transforms.Resize([image_size, image_size]), transforms.ToTensor()])\n",
    "    orig_image = Image.open(file_path).convert('RGB')\n",
    "    orig_image = loader(orig_image).unsqueeze(0)\n",
    "\n",
    "    if gpu:\n",
    "        orig_image = orig_image.cuda()\n",
    "\n",
    "    image_patches = torch.FloatTensor(3, patch_size, patch_size).fill_(c).repeat(batch_size, 1, 1, 1)\n",
    "        \n",
    "    x_output_width = int(math.ceil((x_size*1.0 - patch_size) / stride))\n",
    "    y_output_width = int(math.ceil((y_size*1.0 - patch_size) / stride))\n",
    "\n",
    "    total_number = x_output_width * y_output_width\n",
    "    logit_values = np.zeros((x_output_width, y_output_width), dtype=np.float32)\n",
    "    \n",
    "    num_batches = int(math.ceil(len(patch_positions) * 1.0 / batch_size))\n",
    "    \n",
    "    if gpu:\n",
    "        inc_model = inc_model.cuda()\n",
    "        \n",
    "    temp = inc_model.forward_materialized(orig_image).cpu().data.numpy()\n",
    "    logit_index = np.argmax(temp)\n",
    "    prob = np.max(temp)\n",
    " \n",
    "    locations = torch.zeros([batch_size, 2], dtype=torch.int32)\n",
    "    \n",
    "    for i in range(num_batches):\n",
    "        for j in range(batch_size):\n",
    "            index = j * num_batches + i\n",
    "            if index >= len(patch_positions):\n",
    "                break\n",
    "\n",
    "            x, y = patch_positions[index]\n",
    "            x = x*stride + x0\n",
    "            y = y*stride + y0\n",
    "            x,y = int(x), int(y)\n",
    "            \n",
    "            locations[j, 0] = x\n",
    "            locations[j, 1] = y\n",
    "\n",
    "        if version == 'v1':\n",
    "            logits = inc_model.forward_gpu(image_patches, locations, p_height=patch_size, p_width=patch_size)\n",
    "        else:\n",
    "            logits = inc_model.forward_pytorch(image_patches, locations, p_height=patch_size, p_width=patch_size)\n",
    "            \n",
    "        logits = logits.cpu().data.numpy()[:, logit_index].flatten().tolist()\n",
    "\n",
    "        for logit, j in zip(logits, range(batch_size)):\n",
    "            index = j * num_batches + i\n",
    "            if index >= len(patch_positions):\n",
    "                break\n",
    "            x, y = patch_positions[index]\n",
    "            logit_values[x, y] = logit\n",
    "\n",
    "    del inc_model\n",
    "    gc.collect()\n",
    "\n",
    "    return logit_values, prob, logit_index\n",
    "\n",
    "\n",
    "\n",
    "def adaptive_drilldown_with_model(model1, model2, file_path, patch_size, s2, percentile, speedup, batch_size=128, image_size=224,\n",
    "                       x_size=224, y_size=224, beta=1.0, gpu=True, version='v1',\n",
    "                       n_labels=1000, weights_data=None, loader=None, c=0.0):\n",
    "\n",
    "    final_out_width = int(math.ceil((image_size*1.0-patch_size)/s2))\n",
    "    s1 = round(math.sqrt(speedup/(1-percentile*speedup)) * s2)\n",
    "    percentile *= 100 \n",
    "\n",
    "    #checking for interested regions\n",
    "    temp1, prob, logit_index = inc_inference_e2e_with_model(model1, file_path, patch_size, s1,\n",
    "                                    batch_size=batch_size, beta=beta, image_size=image_size, x_size=x_size,\n",
    "                              y_size=y_size, gpu=gpu, version=version, weights_data=weights_data, loader=loader, c=c)\n",
    "\n",
    "    temp1 = cv2.resize(temp1, (final_out_width, final_out_width), interpolation=cv2.INTER_LINEAR)\n",
    "    threshold = np.percentile(temp1, percentile)\n",
    "    temp1 = np.where(temp1 <= threshold, 0, temp1)\n",
    "    idx = np.argwhere(temp1 <= threshold)\n",
    "    \n",
    "    #drilldown into interested regions\n",
    "    temp2, prob, logit_index = inc_inference_selected_with_model(model2, file_path, patch_size, s2, idx.tolist(),\n",
    "                                    batch_size=batch_size, beta=beta, image_size=image_size,\n",
    "                              x_size=image_size, y_size=image_size, gpu=gpu, version=version,\n",
    "                            weights_data=weights_data, loader=loader, c=c)\n",
    "\n",
    "    \n",
    "    \n",
    "    return np.add(temp1, temp2), prob, logit_index\n",
    "\n",
    "def get_r_drill_down_speedup(datset):\n",
    "    if dataset == \"oct\":\n",
    "        return 0.1, 5\n",
    "    elif dataset == \"chest_xray\":\n",
    "        return 0.4, 2\n",
    "    elif dataset == \"imagenet\":\n",
    "        return 0.25, 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ['blue', 'orange', 'green', 'red']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/snakanda/.local/lib/python2.7/site-packages/matplotlib/cbook/deprecation.py:107: MatplotlibDeprecationWarning: Passing one of 'on', 'true', 'off', 'false' as a boolean is deprecated; use an actual boolean (True/False) instead.\n",
      "  warnings.warn(message, mplDeprecation, stacklevel=1)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x180 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "models = [\"VGG16\", \"ResNet18\", \"Inception3\"]\n",
    "patch_size = 16\n",
    "S2 = 4\n",
    "c = 0.0\n",
    "runs = 4\n",
    "\n",
    "\n",
    "log_file = open('5_1_GPU.log', 'a')\n",
    "log_file.write('============================================\\n')\n",
    "log_file.flush()\n",
    "\n",
    "datasets = [\"oct\", \"chest_xray\", \"imagenet\"]\n",
    "dataset_names = {\"oct\": \"OCT\", \"chest_xray\": \"Chest X-Ray\", \"imagenet\": \"ImageNet\"}\n",
    "image_file_path = '../../../code/python/dog_resized.jpg'\n",
    "\n",
    "\n",
    "def get_tau(model, dataset):\n",
    "    if model == \"VGG16\":\n",
    "        return 0.5\n",
    "    elif model == \"ResNet18\":\n",
    "        if dataset == \"chest_xray\":\n",
    "            return 0.8\n",
    "        else:\n",
    "            return 0.7\n",
    "    elif model == \"Inception3\":\n",
    "        if dataset == \"chest_xray\":\n",
    "            return 0.8\n",
    "        else:\n",
    "            return 0.9\n",
    "    \n",
    "    \n",
    "fig = plt.figure(figsize=(12, 2.5))\n",
    "gs = gridspec.GridSpec(2, 3, height_ratios=[1, 4]) \n",
    "\n",
    "for idx, dataset in enumerate(datasets):\n",
    "    ax1 = plt.subplot(gs[idx])\n",
    "    ax2 = plt.subplot(gs[3+idx])\n",
    "    \n",
    "    \n",
    "    full_inf_mean = []\n",
    "    full_inf_ci = []\n",
    "    ivm_torch_mean = []\n",
    "    ivm_torch_ci = []\n",
    "    ivm_exact_mean = []\n",
    "    ivm_exact_ci = []\n",
    "    ivm_approx_mean = []\n",
    "    ivm_approx_ci = []\n",
    "        \n",
    "        \n",
    "    for model in models:\n",
    "\n",
    "        if model == \"VGG16\":\n",
    "            ivm_model = VGG16\n",
    "            image_size = 224\n",
    "        elif model == \"ResNet18\":\n",
    "            ivm_model = ResNet18\n",
    "            image_size = 224\n",
    "        elif model == \"Inception3\":\n",
    "            ivm_model = Inception3\n",
    "            image_size = 299\n",
    "        \n",
    "        tau = get_tau(model, dataset)\n",
    "\n",
    "        temp_runs = []\n",
    "        cnn_model = ivm_model(gpu=True).eval()\n",
    "        for count in range(runs):\n",
    "            \n",
    "            torch.cuda.synchronize()\n",
    "            prev_time = time.time()\n",
    "            with torch.no_grad():\n",
    "                x, prob, logit_index = full_inference_e2e_with_model(cnn_model, image_file_path, patch_size, S2,\n",
    "                                       batch_size=128, gpu=True, image_size=image_size, x_size=image_size,\n",
    "                                       y_size=image_size, c=c)\n",
    "            \n",
    "            torch.cuda.synchronize()\n",
    "            full_inference_time = time.time() - prev_time\n",
    "            temp_runs.append(full_inference_time)\n",
    "            log_file.write(\",\".join([str(x) for x in [count, model, dataset, \"full\", full_inference_time]])+\"\\n\")\n",
    "            log_file.flush()\n",
    "\n",
    "        del cnn_model  \n",
    "        gc.collect()\n",
    "        m, ci = mean_confidence_interval(temp_runs[1:])\n",
    "        full_inf_mean.append(m)\n",
    "        full_inf_ci.append(ci)\n",
    "        \n",
    "        \n",
    "        temp_runs = []\n",
    "        cnn_model = ivm_model(gpu=True, beta=1.0).eval()\n",
    "        for count in range(runs):\n",
    "            \n",
    "            torch.cuda.synchronize()    \n",
    "            prev_time = time.time()\n",
    "            with torch.no_grad():\n",
    "                x, prob, logit_index = inc_inference_e2e_with_model(cnn_model, image_file_path, patch_size, S2,\n",
    "                                      batch_size=128, beta=1.0, gpu=True, version='v2',\n",
    "                                     image_size=image_size, x_size=image_size, y_size=image_size, c=c)\n",
    "            torch.cuda.synchronize()\n",
    "            inc_inference_time = time.time() - prev_time\n",
    "            temp_runs.append(inc_inference_time)\n",
    "            log_file.write(\",\".join([str(x) for x in [count, model, dataset, \"inc-naive\", inc_inference_time]])+\"\\n\")\n",
    "            log_file.flush()\n",
    "          \n",
    "        del cnn_model\n",
    "        gc.collect()\n",
    "        m, ci = mean_confidence_interval(temp_runs[1:])\n",
    "        ivm_torch_mean.append(m)\n",
    "        ivm_torch_ci.append(ci)\n",
    "        \n",
    "        temp_runs = []\n",
    "        cnn_model = ivm_model(gpu=True, beta=1.0).eval()\n",
    "        for count in range(runs):\n",
    "            \n",
    "            torch.cuda.synchronize()    \n",
    "            prev_time = time.time()\n",
    "            with torch.no_grad():\n",
    "                x, prob, logit_index = inc_inference_e2e_with_model(cnn_model, image_file_path, patch_size, S2,\n",
    "                                      batch_size=128, beta=1.0, gpu=True, version='v1',\n",
    "                                     image_size=image_size, x_size=image_size, y_size=image_size, c=c)\n",
    "\n",
    "            torch.cuda.synchronize()\n",
    "            inc_inference_time = time.time() - prev_time\n",
    "            temp_runs.append(inc_inference_time)\n",
    "            log_file.write(\",\".join([str(x) for x in [count, model, dataset, \"inc\", inc_inference_time]])+\"\\n\")\n",
    "            log_file.flush()\n",
    "           \n",
    "        del cnn_model\n",
    "        m, ci = mean_confidence_interval(temp_runs[1:])\n",
    "        ivm_exact_mean.append(m)\n",
    "        ivm_exact_ci.append(ci)\n",
    "        \n",
    "        \n",
    "        temp_runs = []\n",
    "        cnn_model1 = ivm_model(gpu=True, beta=tau).eval()\n",
    "        cnn_model2 = ivm_model(gpu=True, beta=tau).eval()\n",
    "        r_drill, speedup = get_r_drill_down_speedup(dataset)\n",
    "        for count in range(runs):\n",
    "            \n",
    "            torch.cuda.synchronize()    \n",
    "            prev_time = time.time()\n",
    "            with torch.no_grad():\n",
    "                x, prob, logit_index = adaptive_drilldown_with_model(cnn_model1, cnn_model2, image_file_path, patch_size, S2, r_drill, speedup,\n",
    "                                    batch_size=128, beta=tau, gpu=True, version='v1',\n",
    "                                    image_size=image_size, x_size=image_size, y_size=image_size,\n",
    "                                    c=c)\n",
    "            \n",
    "            torch.cuda.synchronize()\n",
    "            ada_time = time.time() - prev_time\n",
    "            temp_runs.append(ada_time)\n",
    "            log_file.write(\",\".join([str(x) for x in [count, model, dataset, \"inc-aprox\", ada_time]])+\"\\n\")\n",
    "            log_file.flush()\n",
    "\n",
    "        del cnn_model1\n",
    "        del cnn_model2\n",
    "        gc.collect()\n",
    "        m, ci = mean_confidence_interval(temp_runs[1:])\n",
    "        ivm_approx_mean.append(m)\n",
    "        ivm_approx_ci.append(ci)\n",
    "        \n",
    "        \n",
    "    pos = [0.8, 2., 3.2]\n",
    "    width = 0.2\n",
    "\n",
    "    for ax_temp in [ax1, ax2]:\n",
    "        l1 = ax_temp.bar(pos, full_inf_mean, width, color=colors[0], hatch=3*'-',\n",
    "                     yerr=full_inf_ci, ecolor='black', alpha=0.8) \n",
    "        l2 = ax_temp.bar([p + width for p in pos], ivm_torch_mean, width, color=colors[1], hatch=3*'+',\n",
    "                 yerr=ivm_torch_ci, ecolor='black', alpha=0.8)\n",
    "        l3 = ax_temp.bar([p + 2*width for p in pos], ivm_exact_mean, width, color=colors[2], hatch=3*'x',\n",
    "                 yerr=ivm_exact_ci, ecolor='black', alpha=0.8)\n",
    "        l4 = ax_temp.bar([p + 3*width for p in pos], ivm_approx_mean, width, color=colors[3], hatch=3*'*',\n",
    "                 yerr=ivm_approx_ci, ecolor='black', alpha=0.8)\n",
    "    \n",
    "    \n",
    "        ax_temp.set_xticks([p + 1.5*width for p in pos])\n",
    "        ax_temp.set_xticklabels(models)\n",
    "        ax_temp.set_xlim(min(pos)-width, max(pos)+width*4)\n",
    "    \n",
    "    #if idx == 0:\n",
    "    #    ax.set_ylabel('Run Time (s)')\n",
    "\n",
    "    ax1.set_title(dataset_names[dataset]+\"/GPU\")\n",
    "    ax1.set_ylim(70, 80)\n",
    "    ax2.set_ylim(0, 15)\n",
    "\n",
    "    \n",
    "    ax1.spines['bottom'].set_visible(False)\n",
    "    ax2.spines['top'].set_visible(False)\n",
    "    \n",
    "    ax1.xaxis.tick_top()\n",
    "    ax1.tick_params(labeltop='off')\n",
    "    ax2.xaxis.tick_bottom()\n",
    "        \n",
    "    ax1.grid()\n",
    "    ax2.grid()\n",
    "   \n",
    "\n",
    "lgd = fig.legend((l1, l2, l3, l4), ('Naive', 'Naive Inc. Inference-Exact', 'Krypton-Exact', 'Krypton-Approx.'), loc=(0.18, -0.01), ncol=4, frameon=False)\n",
    "plt.savefig('../images/5_1_GPU.pdf', bbox_extra_artists=(lgd,), bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.9, 16.0\n",
      "1.6, 6.2\n",
      "0.7, 4.5\n",
      "3.9, 8.6\n",
      "1.6, 3.1\n",
      "0.7, 2.3\n",
      "3.9, 11.2\n",
      "1.6, 4.4\n",
      "0.7, 2.6\n"
     ]
    }
   ],
   "source": [
    "log_file = open('5_1_GPU.log', 'r')\n",
    "lines = log_file.readlines()[1:]\n",
    "\n",
    "runs = 4\n",
    "count = 0\n",
    "\n",
    "while count < len(lines):\n",
    "    full_inf = []\n",
    "    for r in range(runs):\n",
    "        full_inf.append(float(lines[count].split(\",\")[-1].replace(\"\\n\", \"\")))\n",
    "        count += 1\n",
    "\n",
    "    count += runs\n",
    "    inc_inf = []\n",
    "    for r in range(runs):\n",
    "        inc_inf.append(float(lines[count].split(\",\")[-1].replace(\"\\n\", \"\")))\n",
    "        count += 1\n",
    "    \n",
    "    inc_approx = []\n",
    "    for r in range(runs):\n",
    "        inc_approx.append(float(lines[count].split(\",\")[-1].replace(\"\\n\", \"\")))\n",
    "        count += 1\n",
    "    \n",
    "    m_full, _ = mean_confidence_interval(full_inf[1:])\n",
    "    m_inc, _ = mean_confidence_interval(inc_inf[1:])    \n",
    "    m_approx, _ = mean_confidence_interval(inc_approx[1:]) \n",
    "    \n",
    "    print(\"%.1f, %.1f\"%(m_full/m_inc, m_full/m_approx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
