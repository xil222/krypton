{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torchvision'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-f07395e53786>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;31m# import matplotlib.pyplot as plt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mplot_commons\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_ivm_patch_coordinates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcalculate_ivm_flops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcalculate_flops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_confidence_interval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;31m# random.seed(45)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Work/krypton/paper/current/plots_notebooks/plot_commons.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malexnet\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0malexnet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvgg\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mvgg16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvgg19\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresnet\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mresnet18\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresnet50\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torchvision'"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "import math\n",
    "import numpy as np\n",
    "# import torch\n",
    "# from torchvision.models.alexnet import alexnet\n",
    "# from torchvision.models.vgg import vgg16, vgg19\n",
    "# from torchvision.models.resnet import resnet18, resnet50\n",
    "# from torchvision.models.densenet import densenet121\n",
    "# from torchvision.models.inception import Inception3 as inception3\n",
    "# from torchvision import transforms\n",
    "from PIL import Image\n",
    "import sys\n",
    "import time\n",
    "import random\n",
    "# import cv2\n",
    "# import gc\n",
    "# from matplotlib import gridspec\n",
    "\n",
    "# sys.path.append('../../../code')\n",
    "\n",
    "# from python.commons import full_inference_e2e_with_model, inc_inference_e2e_with_model\n",
    "# from python.vgg16 import VGG16\n",
    "# from python.resnet18 import ResNet18\n",
    "# from python.inception3 import Inception3\n",
    "\n",
    "# from torch.autograd import Variable\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "from plot_commons import get_ivm_patch_coordinates, calculate_ivm_flops, calculate_flops, mean_confidence_interval\n",
    "\n",
    "# random.seed(45)\n",
    "# np.random.seed(45)\n",
    "\n",
    "# torch.set_num_threads(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inc_inference_selected_with_model(inc_model, file_path, patch_size, stride, patch_positions, batch_size=64, beta=1.0,\n",
    "                           x0=0, y0=0, image_size=224, x_size=224, y_size=224, gpu=True, version='v1',\n",
    "                           n_labels=1000, weights_data=None, loader=None, c=0.0):\n",
    "\n",
    "    if loader == None:\n",
    "        loader = transforms.Compose([transforms.Resize([image_size, image_size]), transforms.ToTensor()])\n",
    "    orig_image = Image.open(file_path).convert('RGB')\n",
    "    orig_image = loader(orig_image).unsqueeze(0)\n",
    "\n",
    "    if gpu:\n",
    "        orig_image = orig_image.cuda()\n",
    "\n",
    "    image_patches = torch.FloatTensor(3, patch_size, patch_size).fill_(c).repeat(batch_size, 1, 1, 1)\n",
    "        \n",
    "    x_output_width = int(math.ceil((x_size*1.0 - patch_size) / stride))\n",
    "    y_output_width = int(math.ceil((y_size*1.0 - patch_size) / stride))\n",
    "\n",
    "    total_number = x_output_width * y_output_width\n",
    "    logit_values = np.zeros((x_output_width, y_output_width), dtype=np.float32)\n",
    "    \n",
    "    num_batches = int(math.ceil(len(patch_positions) * 1.0 / batch_size))\n",
    "    \n",
    "    if gpu:\n",
    "        inc_model = inc_model.cuda()\n",
    "        \n",
    "    temp = inc_model.forward_materialized(orig_image).cpu().data.numpy()\n",
    "    logit_index = np.argmax(temp)\n",
    "    prob = np.max(temp)\n",
    " \n",
    "    locations = torch.zeros([batch_size, 2], dtype=torch.int32)\n",
    "    \n",
    "    for i in range(num_batches):\n",
    "        for j in range(batch_size):\n",
    "            index = j * num_batches + i\n",
    "            if index >= len(patch_positions):\n",
    "                break\n",
    "\n",
    "            x, y = patch_positions[index]\n",
    "            x = x*stride + x0\n",
    "            y = y*stride + y0\n",
    "            x,y = int(x), int(y)\n",
    "            \n",
    "            locations[j, 0] = x\n",
    "            locations[j, 1] = y\n",
    "\n",
    "        if version == 'v1':\n",
    "            logits = inc_model.forward_gpu(image_patches, locations, p_height=patch_size, p_width=patch_size)\n",
    "        else:\n",
    "            logits = inc_model.forward_pytorch(image_patches, locations, p_height=patch_size, p_width=patch_size)\n",
    "            \n",
    "        logits = logits.cpu().data.numpy()[:, logit_index].flatten().tolist()\n",
    "\n",
    "        for logit, j in zip(logits, range(batch_size)):\n",
    "            index = j * num_batches + i\n",
    "            if index >= len(patch_positions):\n",
    "                break\n",
    "            x, y = patch_positions[index]\n",
    "            logit_values[x, y] = logit\n",
    "\n",
    "    del inc_model\n",
    "    gc.collect()\n",
    "\n",
    "    return logit_values, prob, logit_index\n",
    "\n",
    "\n",
    "\n",
    "def adaptive_drilldown_with_model(model1, model2, file_path, patch_size, s2, percentile, speedup, batch_size=128, image_size=224,\n",
    "                       x_size=224, y_size=224, beta=1.0, gpu=True, version='v1',\n",
    "                       n_labels=1000, weights_data=None, loader=None, c=0.0):\n",
    "\n",
    "    final_out_width = int(math.ceil((image_size*1.0-patch_size)/s2))\n",
    "    s1 = round(math.sqrt(speedup/(1-percentile*speedup)) * s2)\n",
    "    percentile *= 100 \n",
    "\n",
    "    #checking for interested regions\n",
    "    temp1, prob, logit_index = inc_inference_e2e_with_model(model1, file_path, patch_size, s1,\n",
    "                                    batch_size=batch_size, beta=beta, image_size=image_size, x_size=x_size,\n",
    "                              y_size=y_size, gpu=gpu, version=version, weights_data=weights_data, loader=loader, c=c)\n",
    "\n",
    "    temp1 = cv2.resize(temp1, (final_out_width, final_out_width), interpolation=cv2.INTER_LINEAR)\n",
    "    threshold = np.percentile(temp1, percentile)\n",
    "    temp1 = np.where(temp1 <= threshold, 0, temp1)\n",
    "    idx = np.argwhere(temp1 <= threshold)\n",
    "    \n",
    "    #drilldown into interested regions\n",
    "    temp2, prob, logit_index = inc_inference_selected_with_model(model2, file_path, patch_size, s2, idx.tolist(),\n",
    "                                    batch_size=batch_size, beta=beta, image_size=image_size,\n",
    "                              x_size=image_size, y_size=image_size, gpu=gpu, version=version,\n",
    "                            weights_data=weights_data, loader=loader, c=c)\n",
    "\n",
    "    \n",
    "    \n",
    "    return np.add(temp1, temp2), prob, logit_index\n",
    "\n",
    "def get_r_drill_down_speedup(datset):\n",
    "    if dataset == \"oct\":\n",
    "        return 0.1, 5\n",
    "    elif dataset == \"chest_xray\":\n",
    "        return 0.4, 2\n",
    "    elif dataset == \"imagenet\":\n",
    "        return 0.25, 3\n",
    "    \n",
    "def get_tau(model, dataset):\n",
    "    if model == \"VGG16\":\n",
    "        return 0.5\n",
    "    elif model == \"ResNet18\":\n",
    "        if dataset == \"chest_xray\":\n",
    "            return 0.8\n",
    "        else:\n",
    "            return 0.7\n",
    "    elif model == \"Inception3\":\n",
    "        if dataset == \"chest_xray\":\n",
    "            return 0.8\n",
    "        else:\n",
    "            return 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ['blue', 'orange', 'green', 'red']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x108 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "models = [\"VGG16\", \"ResNet18\", \"Inception3\"]\n",
    "patch_size = 16\n",
    "S2 = 4\n",
    "c = 0.0\n",
    "runs = 4\n",
    "\n",
    "\n",
    "log_file = open('5_1_GPU.log', 'a')\n",
    "log_file.write('============================================\\n')\n",
    "log_file.flush()\n",
    "\n",
    "datasets = [\"oct\", \"chest_xray\", \"imagenet\"]\n",
    "dataset_names = {\"oct\": \"OCT\", \"chest_xray\": \"Chest X-Ray\", \"imagenet\": \"ImageNet\"}\n",
    "image_file_path = '../../../code/python/dog_resized.jpg'\n",
    "\n",
    "    \n",
    "fig = plt.figure(figsize=(12, 1.5))\n",
    "    \n",
    "# fig = plt.figure(figsize=(12, 2.5)) \n",
    "\n",
    "gs = gridspec.GridSpec(1, 3)#, height_ratios=[1, 4]) \n",
    "# axes = plt.subplots(1,3)\n",
    "for idx, dataset in enumerate(datasets):\n",
    "#     ax1 = plt.subplot(1,3, idx+1)\n",
    "    ax1 = plt.subplot(gs[idx])\n",
    "#     ax2 = plt.subplot(gs[3+idx])\n",
    "    \n",
    "    \n",
    "    full_inf_mean = []\n",
    "    full_inf_ci = []\n",
    "    ivm_torch_mean = []\n",
    "    ivm_torch_ci = []\n",
    "    ivm_exact_mean = []\n",
    "    ivm_exact_ci = []\n",
    "    ivm_approx_mean = []\n",
    "    ivm_approx_ci = []\n",
    "        \n",
    "        \n",
    "    for model in models:\n",
    "\n",
    "        if model == \"VGG16\":\n",
    "            ivm_model = VGG16\n",
    "            image_size = 224\n",
    "        elif model == \"ResNet18\":\n",
    "            ivm_model = ResNet18\n",
    "            image_size = 224\n",
    "        elif model == \"Inception3\":\n",
    "            ivm_model = Inception3\n",
    "            image_size = 299\n",
    "        \n",
    "        tau = get_tau(model, dataset)\n",
    "\n",
    "        temp_runs = []\n",
    "        cnn_model = ivm_model(gpu=True).eval()\n",
    "        for count in range(runs):\n",
    "            \n",
    "            torch.cuda.synchronize()\n",
    "            prev_time = time.time()\n",
    "            with torch.no_grad():\n",
    "                x, prob, logit_index = full_inference_e2e_with_model(cnn_model, image_file_path, patch_size, S2,\n",
    "                                       batch_size=128, gpu=True, image_size=image_size, x_size=image_size,\n",
    "                                       y_size=image_size, c=c)\n",
    "            \n",
    "            torch.cuda.synchronize()\n",
    "            full_inference_time = time.time() - prev_time\n",
    "            temp_runs.append(full_inference_time)\n",
    "            log_file.write(\",\".join([str(x) for x in [count, model, dataset, \"full\", full_inference_time]])+\"\\n\")\n",
    "            log_file.flush()\n",
    "\n",
    "        del cnn_model  \n",
    "        gc.collect()\n",
    "        m, ci = mean_confidence_interval(temp_runs[1:])\n",
    "        full_inf_mean.append(m)\n",
    "        full_inf_ci.append(ci)\n",
    "        \n",
    "        \n",
    "#         temp_runs = []\n",
    "#         cnn_model = ivm_model(gpu=True, beta=1.0).eval()\n",
    "#         for count in range(runs):\n",
    "            \n",
    "#             torch.cuda.synchronize()    \n",
    "#             prev_time = time.time()\n",
    "#             with torch.no_grad():\n",
    "#                 x, prob, logit_index = inc_inference_e2e_with_model(cnn_model, image_file_path, patch_size, S2,\n",
    "#                                       batch_size=128, beta=1.0, gpu=True, version='v2',\n",
    "#                                      image_size=image_size, x_size=image_size, y_size=image_size, c=c)\n",
    "#             torch.cuda.synchronize()\n",
    "#             inc_inference_time = time.time() - prev_time\n",
    "#             temp_runs.append(inc_inference_time)\n",
    "#             log_file.write(\",\".join([str(x) for x in [count, model, dataset, \"inc-naive\", inc_inference_time]])+\"\\n\")\n",
    "#             log_file.flush()\n",
    "          \n",
    "#         del cnn_model\n",
    "#         gc.collect()\n",
    "#         m, ci = mean_confidence_interval(temp_runs[1:])\n",
    "#         ivm_torch_mean.append(m)\n",
    "#         ivm_torch_ci.append(ci)\n",
    "        \n",
    "        temp_runs = []\n",
    "        cnn_model = ivm_model(gpu=True, beta=1.0).eval()\n",
    "        for count in range(runs):\n",
    "            \n",
    "            torch.cuda.synchronize()    \n",
    "            prev_time = time.time()\n",
    "            with torch.no_grad():\n",
    "                x, prob, logit_index = inc_inference_e2e_with_model(cnn_model, image_file_path, patch_size, S2,\n",
    "                                      batch_size=128, beta=1.0, gpu=True, version='v1',\n",
    "                                     image_size=image_size, x_size=image_size, y_size=image_size, c=c)\n",
    "\n",
    "            torch.cuda.synchronize()\n",
    "            inc_inference_time = time.time() - prev_time\n",
    "            temp_runs.append(inc_inference_time)\n",
    "            log_file.write(\",\".join([str(x) for x in [count, model, dataset, \"inc\", inc_inference_time]])+\"\\n\")\n",
    "            log_file.flush()\n",
    "           \n",
    "        del cnn_model\n",
    "        m, ci = mean_confidence_interval(temp_runs[1:])\n",
    "        ivm_exact_mean.append(m)\n",
    "        ivm_exact_ci.append(ci)\n",
    "        \n",
    "        \n",
    "        temp_runs = []\n",
    "        cnn_model1 = ivm_model(gpu=True, beta=tau).eval()\n",
    "        cnn_model2 = ivm_model(gpu=True, beta=tau).eval()\n",
    "        r_drill, speedup = get_r_drill_down_speedup(dataset)\n",
    "        for count in range(runs):\n",
    "            \n",
    "            torch.cuda.synchronize()    \n",
    "            prev_time = time.time()\n",
    "            with torch.no_grad():\n",
    "                x, prob, logit_index = adaptive_drilldown_with_model(cnn_model1, cnn_model2, image_file_path, patch_size, S2, r_drill, speedup,\n",
    "                                    batch_size=128, beta=tau, gpu=True, version='v1',\n",
    "                                    image_size=image_size, x_size=image_size, y_size=image_size,\n",
    "                                    c=c)\n",
    "            \n",
    "            torch.cuda.synchronize()\n",
    "            ada_time = time.time() - prev_time\n",
    "            temp_runs.append(ada_time)\n",
    "            log_file.write(\",\".join([str(x) for x in [count, model, dataset, \"inc-aprox\", ada_time]])+\"\\n\")\n",
    "            log_file.flush()\n",
    "\n",
    "        del cnn_model1\n",
    "        del cnn_model2\n",
    "        gc.collect()\n",
    "        m, ci = mean_confidence_interval(temp_runs[1:])\n",
    "        ivm_approx_mean.append(m)\n",
    "        ivm_approx_ci.append(ci)\n",
    "        \n",
    "        \n",
    "    pos = [0.8, 2., 3.2]\n",
    "    width = 0.2\n",
    "\n",
    "    for ax_temp in [ax1]:#, ax2]:\n",
    "        l1 = ax_temp.bar(pos, full_inf_mean, width, color=colors[0], hatch=3*'-',\n",
    "                     yerr=full_inf_ci, ecolor='black', alpha=0.8) \n",
    "#         l2 = ax_temp.bar([p + width for p in pos], ivm_torch_mean, width, color=colors[1], hatch=3*'+',\n",
    "#                  yerr=ivm_torch_ci, ecolor='black', alpha=0.8)\n",
    "        l3 = ax_temp.bar([p + 1*width for p in pos], ivm_exact_mean, width, color=colors[2], hatch=3*'x',\n",
    "                 yerr=ivm_exact_ci, ecolor='black', alpha=0.8)\n",
    "        l4 = ax_temp.bar([p + 2*width for p in pos], ivm_approx_mean, width, color=colors[3], hatch=3*'*',\n",
    "                 yerr=ivm_approx_ci, ecolor='black', alpha=0.8)\n",
    "    \n",
    "    \n",
    "        ax_temp.set_xticks([p + width for p in pos])\n",
    "        ax_temp.set_xticklabels(models)\n",
    "        ax_temp.set_xlim(min(pos)-width, max(pos)+width*4)\n",
    "    \n",
    "    #if idx == 0:\n",
    "    #    ax.set_ylabel('Run Time (s)')\n",
    "\n",
    "    ax1.set_title(dataset_names[dataset]+\"/GPU\")\n",
    "    ax1.set_ylim(0, 15)\n",
    "    #ax2.set_ylim(0, 15)\n",
    "\n",
    "    \n",
    "    #ax1.spines['bottom'].set_visible(False)\n",
    "    #ax2.spines['top'].set_visible(False)\n",
    "    \n",
    "    ax1.xaxis.tick_top()\n",
    "    ax1.tick_params(labeltop='off')\n",
    "    #ax2.xaxis.tick_bottom()\n",
    "        \n",
    "    ax1.grid()\n",
    "    #ax2.grid()\n",
    "   \n",
    "\n",
    "#lgd = fig.legend((l1, l2, l3, l4), ('Naive', 'Naive Inc. Inference-Exact', 'Krypton-Exact', 'Krypton-Approx.'), loc=(0.18, -0.01), ncol=4, frameon=False)\n",
    "#plt.savefig('../images/5_1_GPU.pdf', bbox_extra_artists=(lgd,), bbox_inches='tight')\n",
    "plt.savefig('../images/5_1_GPU.pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "\n",
    "\n",
    "def mean_confidence_interval(data, confidence=0.95):\n",
    "    a = 1.0 * np.array(data)\n",
    "    n = len(a)\n",
    "    m = np.mean(a)\n",
    "    #m, se = np.mean(a), scipy.stats.sem(a)\n",
    "    #h = se * scipy.stats.t.ppf((1 + confidence) / 2., n-1)\n",
    "    #if math.isnan(h):\n",
    "    #    h = 0\n",
    "    \n",
    "    h = 0\n",
    "    return m, h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "708.8, 148.6 51.5\n",
      "593.3, 398.2 444.3\n",
      "70.3, 44.2 885.3\n",
      "472.6, 180.8 81.7\n",
      "97.2, 786.5 322.6\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-852359ab0a06>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mfull_inf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mruns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mfull_inf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlines\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\",\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mcount\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "log_file = open('5_1_GPU.log', 'r')\n",
    "lines = log_file.readlines()[1:]\n",
    "\n",
    "runs = 4\n",
    "count = 0\n",
    "\n",
    "while count < len(lines):\n",
    "    full_inf = []\n",
    "    for r in range(runs):\n",
    "        full_inf.append(float(lines[count].split(\",\")[-1].replace(\"\\n\", \"\")))\n",
    "        count += 1\n",
    "\n",
    "    count += runs\n",
    "    inc_inf = []\n",
    "    for r in range(runs):\n",
    "        inc_inf.append(float(lines[count].split(\",\")[-1].replace(\"\\n\", \"\")))\n",
    "        count += 1\n",
    "    \n",
    "    inc_approx = []\n",
    "    for r in range(runs):\n",
    "        inc_approx.append(float(lines[count].split(\",\")[-1].replace(\"\\n\", \"\")))\n",
    "        count += 1\n",
    "    \n",
    "    m_full, _ = mean_confidence_interval(full_inf[1:])\n",
    "    m_inc, _ = mean_confidence_interval(inc_inf[1:])    \n",
    "    m_approx, _ = mean_confidence_interval(inc_approx[1:]) \n",
    "    \n",
    "    print(\"%.1f, %.1f %.1f\"%(m_full, m_inc, m_approx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
