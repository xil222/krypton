{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision.models.alexnet import alexnet\n",
    "from torchvision.models.vgg import vgg16, vgg19\n",
    "from torchvision.models.resnet import resnet18, resnet50\n",
    "from torchvision.models.densenet import densenet121\n",
    "from torchvision.models.inception import Inception3 as inception3\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import sys\n",
    "import time\n",
    "import random\n",
    "import cv2\n",
    "import gc\n",
    "\n",
    "sys.path.append('../../../code')\n",
    "\n",
    "from python.commons import full_inference_e2e, inc_inference_e2e\n",
    "from python.vgg16 import VGG16\n",
    "from python.resnet18 import ResNet18\n",
    "from python.inception3 import Inception3\n",
    "\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from plot_commons import get_ivm_patch_coordinates, calculate_ivm_flops, calculate_flops, mean_confidence_interval\n",
    "\n",
    "random.seed(45)\n",
    "np.random.seed(45)\n",
    "\n",
    "torch.set_num_threads(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inc_inference_selected(model, file_path, patch_size, stride, patch_positions, batch_size=64, beta=1.0,\n",
    "                           x0=0, y0=0, image_size=224, x_size=224, y_size=224, gpu=True, version='v1',\n",
    "                           n_labels=1000, weights_data=None, loader=None, c=0.0):\n",
    "\n",
    "    if loader == None:\n",
    "        loader = transforms.Compose([transforms.Resize([image_size, image_size]), transforms.ToTensor()])\n",
    "    orig_image = Image.open(file_path).convert('RGB')\n",
    "    orig_image = loader(orig_image).unsqueeze(0)\n",
    "\n",
    "    if gpu:\n",
    "        orig_image = orig_image.cuda()\n",
    "\n",
    "    image_patches = torch.FloatTensor(3, patch_size, patch_size).fill_(c).repeat(batch_size, 1, 1, 1)\n",
    "        \n",
    "    x_output_width = int(math.ceil((x_size*1.0 - patch_size) / stride))\n",
    "    y_output_width = int(math.ceil((y_size*1.0 - patch_size) / stride))\n",
    "\n",
    "    total_number = x_output_width * y_output_width\n",
    "    logit_values = np.zeros((x_output_width, y_output_width), dtype=np.float32)\n",
    "    \n",
    "    num_batches = int(math.ceil(len(patch_positions) * 1.0 / batch_size))\n",
    "    inc_model = model(beta=beta, gpu=gpu, n_labels=n_labels, weights_data=weights_data).eval()\n",
    "    \n",
    "    if gpu:\n",
    "        inc_model = inc_model.cuda()\n",
    "        \n",
    "    temp = inc_model.forward_materialized(orig_image).cpu().data.numpy()\n",
    "    logit_index = np.argmax(temp)\n",
    "    prob = np.max(temp)\n",
    " \n",
    "    locations = torch.zeros([batch_size, 2], dtype=torch.int32)\n",
    "    \n",
    "    for i in range(num_batches):\n",
    "        for j in range(batch_size):\n",
    "            index = j * num_batches + i\n",
    "            if index >= len(patch_positions):\n",
    "                break\n",
    "\n",
    "            x, y = patch_positions[index]\n",
    "            x = x*stride + x0\n",
    "            y = y*stride + y0\n",
    "            x,y = int(x), int(y)\n",
    "            \n",
    "            locations[j, 0] = x\n",
    "            locations[j, 1] = y\n",
    "\n",
    "        if version == 'v1':\n",
    "            logits = inc_model.forward_gpu(image_patches, locations, p_height=patch_size, p_width=patch_size)\n",
    "        else:\n",
    "            logits = inc_model.forward_pytorch(image_patches, locations, p_height=patch_size, p_width=patch_size)\n",
    "            \n",
    "        logits = logits.cpu().data.numpy()[:, logit_index].flatten().tolist()\n",
    "\n",
    "        for logit, j in zip(logits, range(batch_size)):\n",
    "            index = j * num_batches + i\n",
    "            if index >= len(patch_positions):\n",
    "                break\n",
    "            x, y = patch_positions[index]\n",
    "            logit_values[x, y] = logit\n",
    "\n",
    "    del inc_model\n",
    "    gc.collect()\n",
    "\n",
    "    return logit_values, prob, logit_index\n",
    "\n",
    "\n",
    "\n",
    "def adaptive_drilldown(model, file_path, patch_size, s2, percentile, speedup, batch_size=128, image_size=224,\n",
    "                       x_size=224, y_size=224, beta=1.0, gpu=True, version='v1',\n",
    "                       n_labels=1000, weights_data=None, loader=None, c=0.0):\n",
    "\n",
    "    final_out_width = int(math.ceil((image_size*1.0-patch_size)/s2))\n",
    "    s1 = round(math.sqrt(speedup/(1-percentile*speedup)) * s2)\n",
    "    percentile *= 100 \n",
    "\n",
    "    #checking for interested regions\n",
    "    temp1, prob, logit_index = inc_inference_e2e(model, file_path, patch_size, s1,\n",
    "                                    batch_size=batch_size, beta=beta, image_size=image_size, x_size=x_size,\n",
    "                              y_size=y_size, gpu=gpu, version=version, weights_data=weights_data, loader=loader, c=c)\n",
    "\n",
    "    temp1 = cv2.resize(temp1, (final_out_width, final_out_width), interpolation=cv2.INTER_LINEAR)\n",
    "    threshold = np.percentile(temp1, percentile)\n",
    "    temp1 = np.where(temp1 <= threshold, 0, temp1)\n",
    "    idx = np.argwhere(temp1 <= threshold)\n",
    "    \n",
    "    #drilldown into interested regions\n",
    "    temp2, prob, logit_index = inc_inference_selected(model, file_path, patch_size, s2, idx.tolist(),\n",
    "                                    batch_size=batch_size, beta=beta, image_size=image_size,\n",
    "                              x_size=image_size, y_size=image_size, gpu=gpu, version=version,\n",
    "                            weights_data=weights_data, loader=loader, c=c)\n",
    "\n",
    "    \n",
    "    \n",
    "    return np.add(temp1, temp2), prob, logit_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ['blue', 'orange', 'green', 'red']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "models = [\"VGG16\", \"ResNet18\", \"Inception3\"]\n",
    "patch_size = 16\n",
    "S2 = 1\n",
    "c = 0.0\n",
    "gpu = True\n",
    "drill_down_speedup = 2\n",
    "drill_down_ratio = 0.25\n",
    "datasets = [\"oct\", \"chest_xray\", \"imagenet\"]\n",
    "image_file_path = '../../../code/python/dog_resized.jpg'\n",
    "runs = 1\n",
    "\n",
    "def get_tau(model, dataset):\n",
    "    if model == \"VGG16\":\n",
    "        if dataset == \"chest_xray\":\n",
    "            return 0.5\n",
    "        else:\n",
    "            return 0.4\n",
    "    elif model == \"ResNet18\":\n",
    "        return 0.7\n",
    "    elif model == \"Inception3\":\n",
    "        return 0.8\n",
    "    \n",
    "    \n",
    "fig = plt.figure(figsize=(12, 2.5))    \n",
    "for idx, model in enumerate(models):\n",
    "    ax = plt.subplot(1, 3, idx+1)\n",
    "    \n",
    "    if model == \"VGG16\":\n",
    "        ivm_model = VGG16\n",
    "        image_size = 224\n",
    "    elif model == \"ResNet18\":\n",
    "        ivm_model = ResNet18\n",
    "        image_size = 224\n",
    "    elif model == \"Inception3\":\n",
    "        ivm_model = Inception3\n",
    "        image_size = 299\n",
    "\n",
    "    full_inf_mean = []\n",
    "    full_inf_ci = []\n",
    "    ivm_torch_mean = []\n",
    "    ivm_torch_ci = []\n",
    "    ivm_exact_mean = []\n",
    "    ivm_exact_ci = []\n",
    "    ivm_approx_mean = []\n",
    "    ivm_approx_ci = []\n",
    "        \n",
    "        \n",
    "    for dataset in datasets:\n",
    "        tau = get_tau(model, dataset)\n",
    "\n",
    "        temp_runs = []\n",
    "        for count in range(runs):\n",
    "            if gpu:\n",
    "                torch.cuda.synchronize()\n",
    "            prev_time = time.time()\n",
    "            with torch.no_grad():\n",
    "                x, prob, logit_index = full_inference_e2e(ivm_model, image_file_path, patch_size, S2,\n",
    "                                       batch_size=128, gpu=gpu, image_size=image_size, x_size=image_size,\n",
    "                                       y_size=image_size, c=c)\n",
    "            if gpu:\n",
    "                torch.cuda.synchronize()\n",
    "            full_inference_time = time.time() - prev_time\n",
    "            temp_runs.append(full_inference_time)\n",
    "            print(count, model, dataset, inc_inference_time)\n",
    "        gc.collect()\n",
    "        m, ci = mean_confidence_interval(temp_runs)\n",
    "        full_inf_mean.append(m)\n",
    "        full_inf_ci.append(ci)\n",
    "        \n",
    "        \n",
    "        temp_runs = []\n",
    "        for count in range(runs):\n",
    "            if gpu:\n",
    "                torch.cuda.synchronize()    \n",
    "            prev_time = time.time()\n",
    "            with torch.no_grad():\n",
    "                x, prob, logit_index = inc_inference_e2e(ivm_model, image_file_path, patch_size, S2,\n",
    "                                      batch_size=256, beta=1.0, gpu=gpu, version='v2',\n",
    "                                     image_size=image_size, x_size=image_size, y_size=image_size, c=c)\n",
    "            if gpu:\n",
    "                torch.cuda.synchronize()\n",
    "            inc_inference_time = time.time() - prev_time\n",
    "            temp_runs.append(inc_inference_time)\n",
    "            print(count, model, dataset, inc_inference_time)\n",
    "            \n",
    "        gc.collect()\n",
    "        m, ci = mean_confidence_interval(temp_runs)\n",
    "        ivm_torch_mean.append(m)\n",
    "        ivm_torch_ci.append(ci)\n",
    "        \n",
    "        temp_runs = []\n",
    "        for count in range(runs):\n",
    "            if gpu:\n",
    "                torch.cuda.synchronize()    \n",
    "            prev_time = time.time()\n",
    "            with torch.no_grad():\n",
    "                x, prob, logit_index = inc_inference_e2e(ivm_model, image_file_path, patch_size, S2,\n",
    "                                      batch_size=256, beta=1.0, gpu=gpu, version='v1',\n",
    "                                     image_size=image_size, x_size=image_size, y_size=image_size, c=c)\n",
    "            if gpu:\n",
    "                torch.cuda.synchronize()\n",
    "            inc_inference_time = time.time() - prev_time\n",
    "            temp_runs.append(inc_inference_time)\n",
    "            print(count, model, dataset, inc_inference_time)\n",
    "        m, ci = mean_confidence_interval(temp_runs)\n",
    "        ivm_exact_mean.append(m)\n",
    "        ivm_exact_ci.append(ci)\n",
    "        \n",
    "        \n",
    "        temp_runs = []\n",
    "        for count in range(runs):\n",
    "            if gpu:\n",
    "                torch.cuda.synchronize()    \n",
    "            prev_time = time.time()\n",
    "            with torch.no_grad():\n",
    "                x, prob, logit_index = adaptive_drilldown(ivm_model, image_file_path, patch_size, S2, 0.25, 2,\n",
    "                                    batch_size=256, beta=tau, gpu=gpu, version='v1',\n",
    "                                    image_size=image_size, x_size=image_size, y_size=image_size,\n",
    "                                    c=c)\n",
    "            if gpu:\n",
    "                torch.cuda.synchronize()\n",
    "            ada_time = time.time() - prev_time\n",
    "            temp_runs.append(ada_time)\n",
    "            print(count, model, dataset, ada_time)\n",
    "        gc.collect()\n",
    "        m, ci = mean_confidence_interval(temp_runs)\n",
    "        ivm_approx_mean.append(m)\n",
    "        ivm_approx_ci.append(ci)\n",
    "        \n",
    "        \n",
    "    pos = [0.8, 2., 3.2]\n",
    "    width = 0.2\n",
    "\n",
    "    l1 = plt.bar(pos, full_inf_mean, width, color=colors[0], hatch=3*'-',\n",
    "                 yerr=full_inf_ci, ecolor='black', alpha=0.5) \n",
    "    l2 = plt.bar([p + width for p in pos], ivm_torch_mean, width, color=colors[1], hatch=3*'+',\n",
    "             yerr=ivm_torch_ci, ecolor='black', alpha=0.5)\n",
    "    l3 = plt.bar([p + 2*width for p in pos], ivm_exact_mean, width, color=colors[2], hatch=3*'+',\n",
    "             yerr=ivm_exact_ci, ecolor='black', alpha=0.5)\n",
    "    l4 = plt.bar([p + 3*width for p in pos], ivm_approx_mean, width, color=colors[3], hatch=3*'+',\n",
    "             yerr=ivm_approx_ci, ecolor='black', alpha=0.5)\n",
    "    \n",
    "    if idx == 0:\n",
    "        ax.set_ylabel('Run Time (s)')\n",
    "    ax.set_xticks([p + 1.5*width for p in pos])\n",
    "    ax.set_title(model+\"/GPU\")\n",
    "    ax.set_xticklabels(['OCT', 'Chest X-Ray', 'ImageNet'])\n",
    "    plt.xlim(min(pos)-width, max(pos)+width*4)\n",
    "    plt.grid()\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#     gpu=False\n",
    "    \n",
    "#     ax = plt.subplot(2, 3, idx+1)\n",
    "\n",
    "    \n",
    "#     full_inf_mean = []\n",
    "#     full_inf_ci = []\n",
    "#     ivm_exact_mean = []\n",
    "#     ivm_exact_ci = []\n",
    "#     ivm_approx_mean = []\n",
    "#     ivm_approx_ci = []\n",
    "        \n",
    "        \n",
    "#     for dataset in datasets:\n",
    "#         tau = get_tau(model, dataset)\n",
    "\n",
    "#         temp_runs = []\n",
    "#         for count in range(runs):\n",
    "#             if gpu:\n",
    "#                 torch.cuda.synchronize()\n",
    "#             prev_time = time.time()\n",
    "#             with torch.no_grad():\n",
    "#                 x, prob, logit_index = full_inference_e2e(ivm_model, image_file_path, patch_size, S2,\n",
    "#                                        batch_size=16, gpu=gpu, image_size=image_size, x_size=image_size,\n",
    "#                                        y_size=image_size, c=c)\n",
    "#             if gpu:\n",
    "#                 torch.cuda.synchronize()\n",
    "#             full_inference_time = time.time() - prev_time\n",
    "#             temp_runs.append(full_inference_time)\n",
    "#         m, ci = mean_confidence_interval(temp_runs)\n",
    "#         full_inf_mean.append(m)\n",
    "#         full_inf_ci.append(ci)\n",
    "        \n",
    "        \n",
    "#         temp_runs = []\n",
    "#         for count in range(runs):\n",
    "#             if gpu:\n",
    "#                 torch.cuda.synchronize()    \n",
    "#             prev_time = time.time()\n",
    "#             with torch.no_grad():\n",
    "#                 x, prob, logit_index = inc_inference_e2e(ivm_model, image_file_path, patch_size, S2,\n",
    "#                                       batch_size=16, beta=1.0, gpu=gpu, version='v2',\n",
    "#                                      image_size=image_size, x_size=image_size, y_size=image_size, c=c)\n",
    "#             if gpu:\n",
    "#                 torch.cuda.synchronize()\n",
    "#             inc_inference_time = time.time() - prev_time\n",
    "#             temp_runs.append(full_inference_time)\n",
    "#         m, ci = mean_confidence_interval(temp_runs)\n",
    "#         ivm_exact_mean.append(m)\n",
    "#         ivm_exact_ci.append(ci)\n",
    "        \n",
    "        \n",
    "#         temp_runs = []\n",
    "#         for count in range(runs):\n",
    "#             if gpu:\n",
    "#                 torch.cuda.synchronize()    \n",
    "#             prev_time = time.time()\n",
    "#             with torch.no_grad():\n",
    "#                 x, prob, logit_index = adaptive_drilldown(ivm_model, image_file_path, patch_size, S2, 0.25, 2,\n",
    "#                                     batch_size=16, beta=tau, gpu=gpu, version='v2',\n",
    "#                                     image_size=image_size, x_size=image_size, y_size=image_size,\n",
    "#                                     c=c)\n",
    "#             if gpu:\n",
    "#                 torch.cuda.synchronize()\n",
    "#             ada_time = time.time() - prev_time\n",
    "#             temp_runs.append(ada_time)\n",
    "#         m, ci = mean_confidence_interval(temp_runs)\n",
    "#         ivm_approx_mean.append(m)\n",
    "#         ivm_approx_ci.append(ci)\n",
    "        \n",
    "        \n",
    "#     pos = [0.8, 2., 3.2]\n",
    "#     width = 0.2\n",
    "\n",
    "#     l1 = plt.bar(pos, full_inf_mean, width, color=colors[0], hatch=3*'-',\n",
    "#                  yerr=full_inf_ci, ecolor='black', alpha=0.5) \n",
    "#     l3 = plt.bar([p + width for p in pos], ivm_exact_mean, width, color=colors[2], hatch=3*'+',\n",
    "#              yerr=ivm_exact_ci, ecolor='black', alpha=0.5)\n",
    "#     l4 = plt.bar([p + 2*width for p in pos], ivm_approx_mean, width, color=colors[3], hatch=3*'+',\n",
    "#              yerr=ivm_approx_ci, ecolor='black', alpha=0.5)\n",
    "    \n",
    "#     ax.set_ylabel('Run Time (s)')\n",
    "#     ax.set_xticks([p + width for p in pos])\n",
    "#     ax.set_title(model+\"/CPU\")\n",
    "#     ax.set_xticklabels(['OCT', 'Chest X-Ray', 'ImageNet'])\n",
    "#     plt.xlim(min(pos)-width, max(pos)+width*3)\n",
    "#     plt.grid()\n",
    "        \n",
    "   \n",
    "\n",
    "lgd = fig.legend((l1, l2, l3, l4), ('Naive', 'Naive Inc. Inference-Exact', 'Krypton-Exact', 'Krypton-Approx.'), loc=(0.25, -0.01), ncol=4, frameon=False)\n",
    "\n",
    "plt.savefig('../images/5_1.pdf', bbox_extra_artists=(lgd,), bbox_inches='tight')   \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
