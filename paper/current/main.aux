\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{imagenet}
\citation{kermany2018identifying,islam2017abnormality}
\citation{mohanty2016using}
\citation{arbabzadah2016identifying}
\citation{wang2017deep}
\citation{fdaretinopathy,radiologistshortage}
\citation{ribeiro2016should}
\citation{jung2017deep}
\citation{gdpr}
\citation{zeiler2014visualizing}
\@writefile{toc}{\contentsline {section}{Abstract}{1}{section*.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces (a) Using a CNN to predict diabetic retinopathy in an OCT image/scan. (b) Occluding a part of the image changes the prediction probability. (c) By moving the occluding patch, a sensitivity heat map can be produced.\relax }}{1}{figure.caption.3}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:krypton_overview}{{1}{1}{(a) Using a CNN to predict diabetic retinopathy in an OCT image/scan. (b) Occluding a part of the image changes the prediction probability. (c) By moving the occluding patch, a sensitivity heat map can be produced.\relax }{figure.caption.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}}
\citation{zintgraf2017visualizing}
\citation{kermany2018identifying,islam2017abnormality,mohanty2016using,arbabzadah2016identifying,wang2017deep}
\citation{caffemodelzoo,tfmodelzoo}
\citation{dlbook}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Notation used in this paper.\relax }}{3}{table.caption.4}}
\newlabel{table:preliminaries_symbols}{{1}{3}{Notation used in this paper.\relax }{table.caption.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Setup and Preliminaries}{3}{section.2}}
\newlabel{sec:preliminaries}{{2}{3}{Setup and Preliminaries}{section.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Problem Statement and Assumptions}{3}{subsection.2.1}}
\newlabel{sec:problem}{{2.1}{3}{Problem Statement and Assumptions}{subsection.2.1}{}}
\newlabel{eqn:mheight}{{1}{3}{Problem Statement and Assumptions}{equation.2.1}{}}
\newlabel{eqn:mwidth}{{2}{3}{Problem Statement and Assumptions}{equation.2.2}{}}
\newlabel{eqn:patchimpose}{{5}{3}{Problem Statement and Assumptions}{equation.2.5}{}}
\newlabel{eqn:outputval}{{6}{3}{Problem Statement and Assumptions}{equation.2.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Dataflow of CNN Layers}{3}{subsection.2.2}}
\newlabel{sec:cnn_internals}{{2.2}{3}{Dataflow of CNN Layers}{subsection.2.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Simplified illustration of the key layers of a typical CNN. The highlighted cells (dark/red background) show how a small local spatial context in the first input propagates through subsequent layers. (a) Convolution layer (for simplicity sake, bias addition is not shown). (b) ReLU Non-linearity layer. (c) Pooling layer (max pooling). Notation is explained in Table\nonbreakingspace \ref  {table:preliminaries_symbols}.\relax }}{4}{figure.caption.5}}
\newlabel{fig:cnn_simplified}{{2}{4}{Simplified illustration of the key layers of a typical CNN. The highlighted cells (dark/red background) show how a small local spatial context in the first input propagates through subsequent layers. (a) Convolution layer (for simplicity sake, bias addition is not shown). (b) ReLU Non-linearity layer. (c) Pooling layer (max pooling). Notation is explained in Table~\ref {table:preliminaries_symbols}.\relax }{figure.caption.5}{}}
\newlabel{eqn:elementwise_product}{{7}{4}{Dataflow of CNN Layers}{equation.2.7}{}}
\citation{cavigelli2017cbinfer}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Theoretical speedups for popular deep CNN architectures with incremental inference.\relax }}{5}{figure.caption.6}}
\newlabel{fig:redundancy_ratio}{{3}{5}{Theoretical speedups for popular deep CNN architectures with incremental inference.\relax }{figure.caption.6}{}}
\newlabel{eqn:full_local}{{9}{5}{Dataflow of CNN Layers}{equation.2.9}{}}
\newlabel{eqn:full_all}{{10}{5}{Dataflow of CNN Layers}{equation.2.10}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Incremental Inference Optimizations}{5}{section.3}}
\newlabel{sec:exact}{{3}{5}{Incremental Inference Optimizations}{section.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Expected Speedups}{5}{subsection.3.1}}
\newlabel{eqn:inc_local}{{11}{6}{Expected Speedups}{equation.3.11}{}}
\newlabel{eqn:inc_all}{{12}{6}{Expected Speedups}{equation.3.12}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Single Layer Incremental Inference}{6}{subsection.3.2}}
\newlabel{sec:inc_computation}{{3.2}{6}{Single Layer Incremental Inference}{subsection.3.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Simplified illustration of input and output update patches for Convolution/Pooling layers.\relax }}{6}{figure.caption.7}}
\newlabel{fig:dimensions}{{4}{6}{Simplified illustration of input and output update patches for Convolution/Pooling layers.\relax }{figure.caption.7}{}}
\newlabel{eqn:xcoordinate}{{13}{6}{Single Layer Incremental Inference}{equation.3.13}{}}
\newlabel{eqn:patchwidth}{{14}{6}{Single Layer Incremental Inference}{equation.3.14}{}}
\newlabel{eqn:xreadcoordinate}{{15}{6}{Single Layer Incremental Inference}{equation.3.15}{}}
\newlabel{eqn:readpatchwidth}{{16}{6}{Single Layer Incremental Inference}{equation.3.16}{}}
\citation{sellis1988multiple}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Additional notation for Sections\nonbreakingspace \ref  {sec:exact} and\nonbreakingspace \ref  {sec:approx}.\relax }}{7}{table.caption.8}}
\newlabel{table:optimizer_symbols}{{2}{7}{Additional notation for Sections~\ref {sec:exact} and~\ref {sec:approx}.\relax }{table.caption.8}{}}
\newlabel{eqn:readin}{{17}{7}{Single Layer Incremental Inference}{equation.3.17}{}}
\newlabel{eqn:superposition}{{18}{7}{Single Layer Incremental Inference}{equation.3.18}{}}
\newlabel{eqn:callt}{{19}{7}{Single Layer Incremental Inference}{equation.3.19}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Propagating Updates across Layers}{7}{subsection.3.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Illustration of bounding box calculation for differing input update patch locations for element-wise addition and depth-wise concatenation layers in DAG CNNs.\relax }}{7}{figure.caption.9}}
\newlabel{fig:la_operators}{{5}{7}{Illustration of bounding box calculation for differing input update patch locations for element-wise addition and depth-wise concatenation layers in DAG CNNs.\relax }{figure.caption.9}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}Multi-Query Incremental Inference}{7}{subsection.3.4}}
\citation{chetlur2014cudnn}
\citation{moons20160}
\citation{he2017channel}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces \textsc  {BatchedIncrementalInference}\relax }}{8}{algorithm.1}}
\newlabel{alg:incinference}{{1}{8}{\textproc {BatchedIncrementalInference}\relax }{algorithm.1}{}}
\newlabel{alg:line:memcpy_loop}{{7}{8}{\textproc {BatchedIncrementalInference}\relax }{algorithm.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5}Putting it All Together}{8}{subsection.3.5}}
\citation{basiccnnoperations}
\citation{de2011projective}
\citation{luo2016understanding}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces (a) Projective field growth for 1-D Convolution (filter size $2$, stride $1$). (b) Projective field \textit  {thresholding}; $\tau = 5/7$.\relax }}{9}{figure.caption.10}}
\newlabel{fig:pf_truncate}{{6}{9}{(a) Projective field growth for 1-D Convolution (filter size $2$, stride $1$). (b) Projective field \textit {thresholding}; $\tau = 5/7$.\relax }{figure.caption.10}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces (a) Theoretical speedups with projective field thresholding. (b) Mean Square Error between exact and approximate output of final Convolution/Pooling layers.\relax }}{9}{figure.caption.11}}
\newlabel{fig:proj_thresholding}{{7}{9}{(a) Theoretical speedups with projective field thresholding. (b) Mean Square Error between exact and approximate output of final Convolution/Pooling layers.\relax }{figure.caption.11}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Approximate Inference Optimizations}{9}{section.4}}
\newlabel{sec:approx}{{4}{9}{Approximate Inference Optimizations}{section.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Projective Field Thresholding}{9}{subsection.4.1}}
\newlabel{eqn:normal_width_calc}{{21}{10}{Projective Field Thresholding}{equation.4.21}{}}
\newlabel{eqn:check_tau}{{22}{10}{Projective Field Thresholding}{equation.4.22}{}}
\newlabel{eqn:new_width_calc_with_tau}{{23}{10}{Projective Field Thresholding}{equation.4.23}{}}
\newlabel{eqn:new_in_width}{{24}{10}{Projective Field Thresholding}{equation.4.24}{}}
\newlabel{eqn:new_x_coord}{{25}{10}{Projective Field Thresholding}{equation.4.25}{}}
\newlabel{eqn:new_input_width}{{26}{10}{Projective Field Thresholding}{equation.4.26}{}}
\newlabel{eqn:new_output_x}{{27}{10}{Projective Field Thresholding}{equation.4.27}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Adaptive Drill-Down}{10}{subsection.4.2}}
\newlabel{sec:ada-drill-down}{{4.2}{10}{Adaptive Drill-Down}{subsection.4.2}{}}
\newlabel{eqn:adaptive-drill-down-eqn}{{28}{10}{Adaptive Drill-Down}{equation.4.28}{}}
\citation{wang2004image}
\citation{wang2004image}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces (a) Schematic illustration of the adaptive drill-down idea. (b) Conceptual depiction of the effects of $S_1$ and $r_{drill-down}$ on the theoretical speedup.. \relax }}{11}{figure.caption.12}}
\newlabel{fig:adaptive_drill_down}{{8}{11}{(a) Schematic illustration of the adaptive drill-down idea. (b) Conceptual depiction of the effects of $S_1$ and $r_{drill-down}$ on the theoretical speedup.. \relax }{figure.caption.12}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Automated Parameter Tuning}{11}{subsection.4.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces (a) Fitting a second-order curve for SSM against $\tau $ on a sample of the OCT dataset. (b) CDFs of deviation of actual SSIM from the target SSIM ($0.9$) with our auto-tuned $\tau $, which turned out to be $0.5$, $0.7$, and $0.9$ for VGG-16, ResNet-18, and Inception-V3, respectively.\relax }}{11}{figure.caption.13}}
\newlabel{fig:system_tuning}{{9}{11}{(a) Fitting a second-order curve for SSM against $\tau $ on a sample of the OCT dataset. (b) CDFs of deviation of actual SSIM from the target SSIM ($0.9$) with our auto-tuned $\tau $, which turned out to be $0.5$, $0.7$, and $0.9$ for VGG-16, ResNet-18, and Inception-V3, respectively.\relax }{figure.caption.13}{}}
\newlabel{eqn:s1}{{29}{11}{Automated Parameter Tuning}{equation.4.29}{}}
\newlabel{eqn:speedup_bound}{{30}{11}{Automated Parameter Tuning}{equation.4.30}{}}
\citation{kermany2018identifying}
\citation{deng2009imagenet}
\citation{vggnet}
\citation{resnet}
\citation{inception}
\citation{torchvisionmodels}
\@writefile{toc}{\contentsline {section}{\numberline {5}Experimental Evaluation}{12}{section.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}End-to- End Runtimes}{12}{subsection.5.1}}
\newlabel{sec:end_to_end}{{5.1}{12}{End-to- End Runtimes}{subsection.5.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces End-to-end runtimes of \textsc  {Krypton}\nonbreakingspace  and baselines on all 3 datasets, 3 CNNs, and both GPU and CPU.\relax }}{13}{figure.caption.14}}
\newlabel{fig:5_1_all_edited}{{10}{13}{End-to-end runtimes of \system ~ and baselines on all 3 datasets, 3 CNNs, and both GPU and CPU.\relax }{figure.caption.14}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces Speedups with only the incremental inference optimization (occlusion patch stride $S=4$).\relax }}{13}{figure.caption.15}}
\newlabel{fig:5_2_1_edited}{{11}{13}{Speedups with only the incremental inference optimization (occlusion patch stride $S=4$).\relax }{figure.caption.15}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Ablation Study}{13}{subsection.5.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces Speedups with incremental inference combined with only projective field thresholding.\relax }}{13}{figure.caption.16}}
\newlabel{fig:5_2_2_edited}{{12}{13}{Speedups with incremental inference combined with only projective field thresholding.\relax }{figure.caption.16}{}}
\citation{cavigelli2017cbinfer,buckler2018eva}
\citation{motamedi2018resource}
\citation{zeiler2014visualizing,zintgraf2017visualizing,ribeiro2016should}
\citation{simonyan2013deep,selvaraju2017grad,sundararajan2017axiomatic}
\citation{sundararajan2017axiomatic}
\citation{jung2017deep,miller2017explanation}
\citation{buckler2018eva}
\citation{cavigelli2017cbinfer}
\citation{kang2017noscope}
\citation{chirkova2012materialized,gupta1995maintenance,levy1995answering}
\citation{nikolic2014linview}
\citation{zhao2017incremental}
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces Speedups with incremental inference combined with adaptive drill-down. For (a), we set $S_1=16$. For (b), we set $r_{drill\_down}=0.25$).\relax }}{14}{figure.caption.17}}
\newlabel{fig:5_2_3_edited}{{13}{14}{Speedups with incremental inference combined with adaptive drill-down. For (a), we set $S_1=16$. For (b), we set $r_{drill\_down}=0.25$).\relax }{figure.caption.17}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}Summary and Discussion}{14}{subsection.5.3}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Other Related Work}{14}{section.6}}
\citation{sellis1988multiple,le2012scalable}
\citation{park2018verdictdb,garofalakis2001approximate}
\@writefile{toc}{\contentsline {section}{\numberline {7}Conclusions And Future Work}{15}{section.7}}
\bibstyle{unsrt}
\bibdata{main}
\bibcite{imagenet}{{1}{}{{}}{{}}}
\bibcite{kermany2018identifying}{{2}{}{{}}{{}}}
\bibcite{islam2017abnormality}{{3}{}{{}}{{}}}
\bibcite{mohanty2016using}{{4}{}{{}}{{}}}
\bibcite{arbabzadah2016identifying}{{5}{}{{}}{{}}}
\bibcite{wang2017deep}{{6}{}{{}}{{}}}
\bibcite{fdaretinopathy}{{7}{}{{}}{{}}}
\bibcite{radiologistshortage}{{8}{}{{}}{{}}}
\bibcite{ribeiro2016should}{{9}{}{{}}{{}}}
\bibcite{jung2017deep}{{10}{}{{}}{{}}}
\bibcite{gdpr}{{11}{}{{}}{{}}}
\bibcite{zeiler2014visualizing}{{12}{}{{}}{{}}}
\bibcite{zintgraf2017visualizing}{{13}{}{{}}{{}}}
\bibcite{caffemodelzoo}{{14}{}{{}}{{}}}
\bibcite{tfmodelzoo}{{15}{}{{}}{{}}}
\bibcite{dlbook}{{16}{}{{}}{{}}}
\bibcite{cavigelli2017cbinfer}{{17}{}{{}}{{}}}
\bibcite{sellis1988multiple}{{18}{}{{}}{{}}}
\bibcite{chetlur2014cudnn}{{19}{}{{}}{{}}}
\bibcite{moons20160}{{20}{}{{}}{{}}}
\bibcite{he2017channel}{{21}{}{{}}{{}}}
\bibcite{basiccnnoperations}{{22}{}{{}}{{}}}
\bibcite{de2011projective}{{23}{}{{}}{{}}}
\bibcite{luo2016understanding}{{24}{}{{}}{{}}}
\bibcite{wang2004image}{{25}{}{{}}{{}}}
\bibcite{deng2009imagenet}{{26}{}{{}}{{}}}
\bibcite{vggnet}{{27}{}{{}}{{}}}
\bibcite{resnet}{{28}{}{{}}{{}}}
\bibcite{inception}{{29}{}{{}}{{}}}
\bibcite{torchvisionmodels}{{30}{}{{}}{{}}}
\bibcite{buckler2018eva}{{31}{}{{}}{{}}}
\bibcite{motamedi2018resource}{{32}{}{{}}{{}}}
\bibcite{simonyan2013deep}{{33}{}{{}}{{}}}
\bibcite{selvaraju2017grad}{{34}{}{{}}{{}}}
\bibcite{sundararajan2017axiomatic}{{35}{}{{}}{{}}}
\bibcite{miller2017explanation}{{36}{}{{}}{{}}}
\bibcite{kang2017noscope}{{37}{}{{}}{{}}}
\bibcite{chirkova2012materialized}{{38}{}{{}}{{}}}
\bibcite{gupta1995maintenance}{{39}{}{{}}{{}}}
\bibcite{levy1995answering}{{40}{}{{}}{{}}}
\bibcite{nikolic2014linview}{{41}{}{{}}{{}}}
\bibcite{zhao2017incremental}{{42}{}{{}}{{}}}
\bibcite{le2012scalable}{{43}{}{{}}{{}}}
\@writefile{toc}{\contentsline {section}{References}{16}{section*.19}}
\bibcite{park2018verdictdb}{{44}{}{{}}{{}}}
\bibcite{garofalakis2001approximate}{{45}{}{{}}{{}}}
\bibcite{kingma2014adam}{{46}{}{{}}{{}}}
\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces Interactive mode execution of incremental inference with $G$s of different sizes\relax }}{17}{figure.caption.20}}
\newlabel{fig:interactive_experiment}{{14}{17}{Interactive mode execution of incremental inference with $G$s of different sizes\relax }{figure.caption.20}{}}
\@writefile{toc}{\contentsline {section}{\numberline {A}Interactive Mode Execution}{17}{appendix.A}}
\@writefile{toc}{\contentsline {section}{\numberline {B}Integration into PyTorch}{17}{appendix.B}}
\newlabel{sec:pytorch_integration}{{B}{17}{Integration into PyTorch}{appendix.B}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {15}{\ignorespaces Custom GPU Kernel integration architecture\relax }}{17}{figure.caption.21}}
\newlabel{fig:custom_kernel_integration}{{15}{17}{Custom GPU Kernel integration architecture\relax }{figure.caption.21}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {16}{\ignorespaces Illustration of special cases for which actual output size will be smaller than the value given by Equation\nonbreakingspace (\ref  {eqn:xcoordinate}). (a) and (b) show cases where the filter stride is equal to the filter size. (c) and (d) show situations where the position of the modified patch affecting the size of the output patch.\relax }}{17}{figure.caption.22}}
\newlabel{fig:less_one_example}{{16}{17}{Illustration of special cases for which actual output size will be smaller than the value given by Equation~(\ref {eqn:xcoordinate}). (a) and (b) show cases where the filter stride is equal to the filter size. (c) and (d) show situations where the position of the modified patch affecting the size of the output patch.\relax }{figure.caption.22}{}}
\@writefile{toc}{\contentsline {section}{\numberline {C}Special Cases for Incremental Inference}{17}{appendix.C}}
\citation{luo2016understanding}
\citation{kingma2014adam}
\citation{sundararajan2017axiomatic}
\newlabel{tocindent-1}{0pt}
\newlabel{tocindent0}{0pt}
\newlabel{tocindent1}{7.29999pt}
\newlabel{tocindent2}{11.49998pt}
\newlabel{tocindent3}{0pt}
\providecommand\NAT@force@numbers{}\NAT@force@numbers
\newlabel{eqn:width_subtract}{{31}{18}{Special Cases for Incremental Inference}{equation.C.31}{}}
\@writefile{toc}{\contentsline {section}{\numberline {D}Effective Projective Field Size}{18}{appendix.D}}
\@writefile{toc}{\contentsline {section}{\numberline {E}Fine-tuning CNNs}{18}{appendix.E}}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Train-validation-test split size for each dataset.\relax }}{18}{table.caption.23}}
\newlabel{tbl:dataset_sizes}{{3}{18}{Train-validation-test split size for each dataset.\relax }{table.caption.23}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4}{\ignorespaces Train and test accuracies after fine-tuning.\relax }}{18}{table.caption.24}}
\newlabel{tbl:finetune_accuracies}{{4}{18}{Train and test accuracies after fine-tuning.\relax }{table.caption.24}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {17}{\ignorespaces \leavevmode {\color  {red}Peak GPU memory usage when performing CNN inference on a batch of 128 images.}\relax }}{18}{figure.caption.25}}
\newlabel{fig:mem_overhead}{{17}{18}{\red {Peak GPU memory usage when performing CNN inference on a batch of 128 images.}\relax }{figure.caption.25}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {18}{\ignorespaces \leavevmode {\color  {red}Comparison of integrated gradients method against OBE. (a) Heat maps generated by integrated gradients method with a step size of 50. The three color channel gradients of a pixels at the same point are aggregated using L$2$ norm}\relax }}{18}{figure.caption.26}}
\newlabel{fig:igd}{{18}{18}{\red {Comparison of integrated gradients method against OBE. (a) Heat maps generated by integrated gradients method with a step size of 50. The three color channel gradients of a pixels at the same point are aggregated using L$2$ norm}\relax }{figure.caption.26}{}}
\@writefile{toc}{\contentsline {section}{\numberline {F}Memory Overhead of IVM}{18}{appendix.F}}
\newlabel{sec:mem_overhead}{{F}{18}{Memory Overhead of IVM}{appendix.F}{}}
\@writefile{toc}{\contentsline {section}{\numberline {G}Visual Examples}{18}{appendix.G}}
\newlabel{sec:visual_examples}{{G}{18}{Visual Examples}{appendix.G}{}}
\@writefile{toc}{\contentsline {section}{\numberline {H}Integrated Gradients Method}{18}{appendix.H}}
\newlabel{sec:igd}{{H}{18}{Integrated Gradients Method}{appendix.H}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {19}{\ignorespaces Occlusion heat maps for sample images (CNN model = VGG16, occlusion patch size = 16, patch color = black, occlusion patch stride $(S\nonbreakingspace or\nonbreakingspace S_2)$ = 4. For \textit  {OCT} $r_{drill\_down}=0.1$ and $\mathit  {target}=5$. For \textit  {Chest X-Ray} $r_{drill\_down}=0.4$ and $\mathit  {target}=2$. For \textit  {ImageNet} $r_{drill\_down}=0.25$ and $\mathit  {target}=3$). \leavevmode {\color  {red}For a projective field threshold value of $0.3$ we see significant degradation of heat map quality due to the significant information loss from truncation.}\relax }}{19}{figure.caption.27}}
\newlabel{fig:visual_examples}{{19}{19}{Occlusion heat maps for sample images (CNN model = VGG16, occlusion patch size = 16, patch color = black, occlusion patch stride $(S~or~S_2)$ = 4. For \textit {OCT} $r_{drill\_down}=0.1$ and $\mathit {target}=5$. For \textit {Chest X-Ray} $r_{drill\_down}=0.4$ and $\mathit {target}=2$. For \textit {ImageNet} $r_{drill\_down}=0.25$ and $\mathit {target}=3$). \red {For a projective field threshold value of $0.3$ we see significant degradation of heat map quality due to the significant information loss from truncation.}\relax }{figure.caption.27}{}}
\newlabel{TotPages}{{19}{19}{}{page.19}{}}
