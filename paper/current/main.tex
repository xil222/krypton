%!TEX root = <main.tex>
\documentclass[10pt, sigconf]{acmart}

% Copyright
%\setcopyright{none}
%\setcopyright{acmcopyright}
%\setcopyright{acmlicensed}
% \setcopyright{rightsretained}
%\setcopyright{usgov}
%\setcopyright{usgovmixed}
%\setcopyright{cagov}
%\setcopyright{cagovmixed}
%\settopmatter{printacmref=false}
%\renewcommand\footnotetextcopyrightpermission[1]{} % removes footnote with 
%\pagestyle{plain} % removes running headers

\usepackage[font=small,labelfont=bf]{caption}
\usepackage{graphicx,xspace,verbatim,comment}
\usepackage{hyperref,array,color,balance,multirow}
\usepackage{balance,float,url,amsfonts,alltt}
\usepackage{mathtools,rotating,amsmath,amssymb}
\usepackage{color,ifpdf,fancyvrb}
\usepackage{etoolbox,listings,subcaption}
\usepackage{bigstrut,morefloats,pbox}
\usepackage{amsmath}
\usepackage{algorithm}
\usepackage[noend]{algpseudocode}
\usepackage{booktabs}
\usepackage{bm}

\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}{Proposition}[section]
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{definition}{Definition}[section]

\DeclarePairedDelimiter\ceil{\lceil}{\rceil}
\DeclarePairedDelimiter\floor{\lfloor}{\rfloor}

\newcommand{\eat}[1]{}
\newcommand{\red}{\textcolor{red}}
\newcommand{\system}{\textsc{Krypton}}

\makeatletter
\def\BState{\State\hskip-\ALG@thistlm}
\makeatother 

\newenvironment{packeditems}{
\begin{itemize}
  \setlength{\itemsep}{1pt}
  \setlength{\parskip}{0pt}
  \setlength{\parsep}{0pt}
}{\end{itemize}}

\newenvironment{packedenums}{
\begin{enumerate}
  \setlength{\itemsep}{1pt}
  \setlength{\parskip}{0pt}
  \setlength{\parsep}{0pt}
}{\end{enumerate}}


\newcolumntype{P}[1]{>{\centering\arraybackslash}p{#1}}

\DeclareMathOperator*{\argmin}{arg\,min}


\begin{document}
\emergencystretch 1em

\title{Incremental and Approximate Inference for\\Faster Occlusion-based Deep CNN Explanations}

%\author{Anonymous Author(s)}
% \affiliation{
  % \institution{University of California, San Diego}
% }
% \email{@eng.ucsd.edu}


\begin{abstract}
Deep Convolutional Neural Networks (CNNs) now match human accuracy in many image recognition tasks. This has lead to increasing adoption of deep CNNs in e-commerce, radiology, and other domains. Naturally, ``explaining'' CNN predictions is a key concern for many users. Since the internal working of CNNs are unintuitive for non-technical users, occlusion-based explanations are popular for determining which parts of an input image contribute the most to a given prediction. One occludes a region of the image using a patch and moves this patch across the image to yield a heat map of changes to the prediction probability. Alas, this approach is computationally expensive due to the large number of re-inference requests produced, which could waste human time and raise resource costs. In this paper, we resolve this issue by casting occlusion-based CNN explanations as a new instance of the incremental view maintenance problem. We create a novel and comprehensive algebraic framework for incremental CNN inference that combines materialized views with multi-query optimization to avoid computational redundancy across re-inference requests. We then introduce two approximate inference optimizations that exploit the semantics of CNNs and the occlusion task to further reduce runtimes. We prototype our ideas in Python to create a tool we call \textsc{Krypton} that can support both CPUs and GPUs. Experiments with real data and CNNs show that \textsc{Krypton} reduces runtimes by up to 5x (14x) to produce exact (approximate) heat maps without raising resource requirements.
\end{abstract}

\maketitle

\input{introduction}

% \input{background}

\input{system_overview}

\input{optimizer}

\input{experiments}

\section{Other Related Work}

\vspace{2mm}
\noindent \textbf{Query Optimization.} Our work is inspired by the long line of work on incremental view maintenance (IVM) based query processing \cite{chirkova2012materialized,gupta1995maintenance,levy1995answering}.
The IVM approach presented in this paper falls into the broader category of \textit{``lazy maintenance''} strategy.
While there are many work in this context, most relevant to our work are \cite{nikolic2014linview} and \cite{zhao2017incremental}.
\cite{nikolic2014linview} extended the IVM concept to support IVM of linear algebra operators as opposed to classical database queries.
\cite{zhao2017incremental} extended the IVM concept to support multi-dimensional array data model with support for both relational style functions (e.g. filter and join) and also array style functions (e.g. smoothing and cross-matching).
The spatially localized transformations explained in Section 2.2 can be thought of as a form of \textit{``spatial array join''} introduced in \cite{zhao2017incremental}.
However, the focus of \cite{zhao2017incremental} is on supporting efficient IVM for distributed sparse arrays by reducing the communication and chunk reassignment where as the focus of this work is on creating a comprehensive algebraic framework for the OBE workload by applying incremental inference optimization.
We also takes into account the characteristics of human perception and semantics of CNN models to introduce approximate inference optimizations for OBE workload.

Our work also takes inspirations from the multi-query optimization (MQO) \cite{sellis1988multiple,le2012scalable} and approximate query processing (AQP) \cite{park2018verdictdb,garofalakis2001approximate} literature.
We cast the multiple re-inference requests required for the OBE workload as multiple queries and apply MQO strategies.
To the best of our knowledge, ours is the first to integrate IVM-style techniques with an MQO-style technique for optimizing CNN inference.
The focus of existing AQP approaches is on answering analytical queries over relational data efficiently by trading-off the statistical error.
In this work, we extend the AQP concepts to support CNN explanation queries over image data which trade-offs perceived quality of the heat maps for efficiency.


\vspace{2mm}
\noindent \textbf{Multimedia DBMSs.} There is prior work in the database and multimedia literatures on multimedia DBMSs \cite{adjeroh1997multimedia,kalipsiz2000multimedia}.
However, the focus of these work is on retrieval which includes content-based image retrieval (CBIR) and video retrieval using similarity searches or indices.
Such systems are orthogonal to our work, since we focus on OBE for deep CNNs.
CBinfer is a system for change based approximate evaluation of CNNs for real-time object recognition in video~\cite{cavigelli2017cbinfer}.
NoScope is a system to detect objects in video streams using cascades of CNNs \cite{kang2017noscope}.
\system~ is orthogonal to them, since it focuses on OBE, not object recognition.
One could integrate \system~ with CBinfer and NoScope to explain the CNN predictions.


\section{Conclusions And Future Work}

\bibliographystyle{unsrt}
\bibliography{main}

\input{appendix}
\end{document}