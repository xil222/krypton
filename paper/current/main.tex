%!TEX root = <main.tex>
\documentclass[10pt, sigconf]{acmart}

% Copyright
%\setcopyright{none}
%\setcopyright{acmcopyright}
%\setcopyright{acmlicensed}
% \setcopyright{rightsretained}
%\setcopyright{usgov}
%\setcopyright{usgovmixed}
%\setcopyright{cagov}
%\setcopyright{cagovmixed}
%\settopmatter{printacmref=false}
%\renewcommand\footnotetextcopyrightpermission[1]{} % removes footnote with 
%\pagestyle{plain} % removes running headers

\usepackage[font=small,labelfont=bf]{caption}
\usepackage{graphicx,xspace,verbatim,comment}
\usepackage{hyperref,array,color,balance,multirow}
\usepackage{balance,float,url,amsfonts,alltt}
\usepackage{mathtools,rotating,amsmath,amssymb}
\usepackage{color,ifpdf,fancyvrb}
\usepackage{etoolbox,listings,subcaption}
\usepackage{bigstrut,morefloats,pbox}
\usepackage{amsmath}
\usepackage{algorithm}
\usepackage[noend]{algpseudocode}
\usepackage{booktabs}
\usepackage{bm}

\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}{Proposition}[section]
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{definition}{Definition}[section]

\DeclarePairedDelimiter\ceil{\lceil}{\rceil}
\DeclarePairedDelimiter\floor{\lfloor}{\rfloor}

\newcommand{\eat}[1]{}
\newcommand{\red}{\textcolor{red}}
\newcommand{\system}{\textsc{Krypton}}

\makeatletter
\def\BState{\State\hskip-\ALG@thistlm}
\makeatother 

\newenvironment{packeditems}{
\begin{itemize}
  \setlength{\itemsep}{1pt}
  \setlength{\parskip}{0pt}
  \setlength{\parsep}{0pt}
}{\end{itemize}}

\newenvironment{packedenums}{
\begin{enumerate}
  \setlength{\itemsep}{1pt}
  \setlength{\parskip}{0pt}
  \setlength{\parsep}{0pt}
}{\end{enumerate}}


\newcolumntype{P}[1]{>{\centering\arraybackslash}p{#1}}

\DeclareMathOperator*{\argmin}{arg\,min}


\begin{document}
\emergencystretch 1em

\title{Incremental and Approximate Inference for\\Faster Occlusion-based Deep CNN Explanations}

% \author{Supun Nakandala, Arun Kumar, and Yannis Papakonstantinou}
% \affiliation{
%   \institution{University of California, San Diego}
% }
% \email{{snakanda,arunkk,yannis}@eng.ucsd.edu}


\begin{abstract}
Deep Convolutional Neural Networks (CNNs) now match human accuracy in many image prediction tasks, resulting in a growing adoption in e-commerce, radiology, and other domains. Naturally, ``explaining'' CNN predictions is a key concern for many users. Since the internal workings of CNNs are unintuitive for most users, \textit{occlusion-based explanations} (OBE) are popular for understanding which parts of a image matter most for a prediction. One occludes a region of the image using a patch and moves it around to produce a \textit{heat map} of changes to the prediction probability. Alas, this approach is computationally expensive due to the large number of re-inference requests produced, which wastes time and raises resource costs. We tackle this issue by casting the OBE task as a new instance of the classical incremental view maintenance problem. We create a novel and comprehensive algebraic framework for incremental CNN inference combining materialized views with multi-query optimization to reduce computational costs. We then present two novel approximate inference optimizations that exploit the semantics of CNNs and the OBE task to further reduce runtimes. We prototype our ideas in Python to create a tool we call \textsc{Krypton} that supports both CPUs and GPUs. Experiments with real data and CNNs show that \textsc{Krypton} reduces runtimes by up to $5$X (resp.~$35$X) to produce exact (resp.~high-quality approximate) results without raising resource requirements.
\end{abstract}

\maketitle

\input{introduction}

% \input{background}

\input{system_overview}

\input{optimizer}

\input{experiments}

\section{Other Related Work}

\vspace{2mm}
\noindent \textbf{Methods for explaining CNN Predictions.}
\red{Perturbation based and gradient based are the two main types of CNN explainability approaches.
Perturbation based methods \cite{zeiler2014visualizing,zintgraf2017visualizing,ribeiro2016should} observe the output of the model by modifying regions of the input image.
OBE falls into this category.}
% Another recently introduced perturbation based method is the \textit{Prediction Difference Analysis} method \cite{zintgraf2017visualizing}, which modifies individual pixel values which can be considered as a special case of OBE with a patch size of one with different values.}
\red{Gradient-based methods \cite{simonyan2013deep,selvaraju2017grad,sundararajan2017axiomatic} generate a sensitivity heat map by computing the partial derivatives of model output with respect to every input pixel using the backpropagation method.
\textit{Axiomatic Attribution for Deep Networks using Integrated Gradients} method \cite{sundararajan2017axiomatic} is a recently proposed method which falls into this category.
We evaluated OBE with integrated gradients methods and found comparable results (see Appendix \ref{sec:igd}).} 

% Even though gradient approaches require only a single forward inference and a single backpropagation to generate the sensitivity heat map, the output may not be very intuitive and hard to understand because the salient pixels tend to spread over a very large area of the input image.
% Despite being time-consuming, in most real world use cases such as in medical imaging, practitioners tend to use occlusion experiments, a perturbation based approach, as the preferred approach for explanations as they produce high quality fine grained sensitivity heat maps using a process which is very intuitive to the human observer ~\cite{zeiler2014visualizing,jung2017deep,miller2017explanation}.

\vspace{2mm}
\noindent \textbf{Accelerating CNN Inference.} 
\red{EVA$^2$ \cite{buckler2018eva} is a custom software-hardware integrated stack for exploiting temporal redundancy across video frames.
While one can map OBE to a video, EVA$^2$ will still perform motion estimation fully on all frames.
Our IVM can avoid such spatial redundancy and our MQO optimizations amortizes hardware overheads, which makes \system ~complementary to EVA$^2$.}
CBinfer is a video analytics tool for change-based approximate CNN inference that can accelerate real-time object recognition in video~\cite{cavigelli2017cbinfer}. Our work also deals with incremental and approximate CNN inference, but our ideas exploit the specific properties of the OBE workload, not general object recognition in video. NoScope is a system to accelerate object detection in video streams using model cascades~\cite{kang2017noscope}.
Our focus is on accelerating the OBE workload, not object recognition or video.
Overall, both these tools are orthogonal to our focus.


\vspace{2mm}
\noindent \textbf{Query Optimization.}
Our work is inspired by the long line of work on incremental view maintenance (IVM) in databases~\cite{chirkova2012materialized, gupta1995maintenance, levy1995answering}, but this is the first work to use the IVM lens for the occlusion-based CNN explanation workload. Our novel algebraic IVM framework for CNN inference is closely tied to the dataflow of CNN layers, which transform tensors in non-trivial ways. Closely related to our work is the IVM framework for linear algebra in~\cite{nikolic2014linview}. They focus on bulk matrix operators and incremental addition of rows to the data matrix. We do not deal with bulk matrix operators or additions of rows, but more fine-grained CNN inference computations and in-place updates to image pixels due to occlusions. Also closely related is the IVM framework for distributed multi-dimensional array database queries in~\cite{zhao2017incremental}. An interesting connection is that CNN layers with local spatial context (Section 2.2) can be viewed as a variant of spatial array join-aggregate queries. But our framework enables end-to-end incremental inference for entire CNNs, not just one-off spatial queries involving data materialization and loading. Our focus is also on popular deep learning environments, not array databases. Finally, we also go beyond algebraic IVM ideas to further exploit CNN-specific semantics and human perception properties in our problem setting.

Our work is also inspired by the multi-query optimization (MQO) literature~\cite{sellis1988multiple,le2012scalable}. But we focus on CNN inference, not relational queries. To the best of our knowledge, ours is the first work to present an MQO-style optimization combined with IVM for optimizing CNN inference for occlusion-based explanations.
Our approximate inference optimizations are inspired by approximate query processing (AQP) techniques~\cite{park2018verdictdb,garofalakis2001approximate}. But unlike statistical approximations of aggregations over relations, our techniques are novel CNN-specific and human perception-oriented heuristic approximations tailored to reducing the computational cost of CNN inference for the OBE workload.

% \vspace{2mm}
% \noindent \textbf{Multimedia DBMSs.} 
% There is much work in the database and multimedia literatures on multimedia DBMSs~\cite{adjeroh1997multimedia,kalipsiz2000multimedia}. The main focus of such work is on retrieval, including content-based image retrieval (CBIR) and video retrieval using similarity search or indexes. Our work is orthogonal to this body of work since we focus on accelerating CNN explanations, not multimedia retrieval queries. CBinfer is a video analytics tool for change-based approximate CNN inference that can accelerate real-time object recognition in video~\cite{cavigelli2017cbinfer}. Our work also deals with incremental and approximate CNN inference, but our ideas exploit the specific properties of the OBE workload, not general object recognition in video. NoScope is a system to accelerate object detection in video streams using model cascades~\cite{kang2017noscope}. Our focus is on accelerating the OBE workload, not object recognition or video. Overall, both these tools are orthogonal to our focus.

\section{Conclusions And Future Work}
Deep CNNs are gaining widespread adoption for image prediction tasks but their internal workings are unintuitive for most users. Thus, occlusion-based explanations (OBE) have become a popular mechanism for non-technical users to understand CNN predictions. But OBE is highly compute-intensive due to the large number of CNN inference requests produced. In this work, we formalize OBE from a data management standpoint and introduce several novel database-inspired optimization techniques to speed up OBE. Our techniques span exact incremental inference and multi-query optimization for CNN inference, as well as CNN-specific and human perception-aware approximate inference. Overall, our ideas yield even over an order of magnitude speedups for OBE in both CPU and GPU environments.

% The applicability of our optimizations goes beyond just the OBE workload.
% As for future work, we plan to apply our ideas to other complex visual recognition tasks and video analytics. It is also interesting future work to generalize our framework to other CNN explanation mechanisms and data types.

\red{The applicability of our optimizations goes beyond just the OBE workload.
Our IVM approach can be applied to optimize a broad range of complex visual recognition and video analytics tasks where the contents of subsequent frames does not change significantly.
On the other hand one can also treat the IVM friendliness of a CNN as a selection criteria when selecting a CNN architecture for a particular task.
It is also interesting future work to generalize our framework to other types of models and data types.
}

\pagebreak


\bibliographystyle{unsrt}
\bibliography{main}

\input{appendix}
\end{document}